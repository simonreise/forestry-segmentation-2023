{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7ac8aa",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: right;font-family:Times New Roman\">Приложение Б-4</div>\n",
    "# <div style=\"text-align: center;font-family:Times New Roman\">Обучение моделей</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17bb23",
   "metadata": {},
   "source": [
    "# Model training\n",
    "# Обучение моделей\n",
    "---\n",
    "In this notebook convolutional neural networks for tree species, forest types and bonitet modeling are trained, tested and used for vegetation mapping\n",
    "\n",
    "В данном блокноте происходит обучение и тестирование сверточных нейронных сетей для моделирования преобладающей породы, типов леса и бонитета, а также при помощи применения этих моделей создаются карты растительности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08e975",
   "metadata": {},
   "source": [
    "### Importing dependencies\n",
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "later-mercury",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\geo\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import fiona\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.merge\n",
    "import rasterio.fill\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.windows import Window\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ab92d",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c552e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating tiles / генерация тайлов\n",
    "tiles = []\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "x2 = 128\n",
    "y2 = 128\n",
    "for i in range (0,632,1):\n",
    "    for i in range(0,1089,1):\n",
    "        tiles.append((x1,y1,x2,y2))\n",
    "        y1 +=128\n",
    "        y2 +=128\n",
    "    y1=0\n",
    "    y2=128\n",
    "    x1+=128\n",
    "    x2+=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4972e8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 128, 128),\n",
       " (0, 128, 128, 256),\n",
       " (0, 256, 128, 384),\n",
       " (0, 384, 128, 512),\n",
       " (0, 512, 128, 640),\n",
       " (0, 640, 128, 768),\n",
       " (0, 768, 128, 896),\n",
       " (0, 896, 128, 1024),\n",
       " (0, 1024, 128, 1152),\n",
       " (0, 1152, 128, 1280),\n",
       " (0, 1280, 128, 1408),\n",
       " (0, 1408, 128, 1536),\n",
       " (0, 1536, 128, 1664),\n",
       " (0, 1664, 128, 1792),\n",
       " (0, 1792, 128, 1920),\n",
       " (0, 1920, 128, 2048),\n",
       " (0, 2048, 128, 2176),\n",
       " (0, 2176, 128, 2304),\n",
       " (0, 2304, 128, 2432),\n",
       " (0, 2432, 128, 2560),\n",
       " (0, 2560, 128, 2688),\n",
       " (0, 2688, 128, 2816),\n",
       " (0, 2816, 128, 2944),\n",
       " (0, 2944, 128, 3072),\n",
       " (0, 3072, 128, 3200),\n",
       " (0, 3200, 128, 3328),\n",
       " (0, 3328, 128, 3456),\n",
       " (0, 3456, 128, 3584),\n",
       " (0, 3584, 128, 3712),\n",
       " (0, 3712, 128, 3840),\n",
       " (0, 3840, 128, 3968),\n",
       " (0, 3968, 128, 4096),\n",
       " (0, 4096, 128, 4224),\n",
       " (0, 4224, 128, 4352),\n",
       " (0, 4352, 128, 4480),\n",
       " (0, 4480, 128, 4608),\n",
       " (0, 4608, 128, 4736),\n",
       " (0, 4736, 128, 4864),\n",
       " (0, 4864, 128, 4992),\n",
       " (0, 4992, 128, 5120),\n",
       " (0, 5120, 128, 5248),\n",
       " (0, 5248, 128, 5376),\n",
       " (0, 5376, 128, 5504),\n",
       " (0, 5504, 128, 5632),\n",
       " (0, 5632, 128, 5760),\n",
       " (0, 5760, 128, 5888),\n",
       " (0, 5888, 128, 6016),\n",
       " (0, 6016, 128, 6144),\n",
       " (0, 6144, 128, 6272),\n",
       " (0, 6272, 128, 6400),\n",
       " (0, 6400, 128, 6528),\n",
       " (0, 6528, 128, 6656),\n",
       " (0, 6656, 128, 6784),\n",
       " (0, 6784, 128, 6912),\n",
       " (0, 6912, 128, 7040),\n",
       " (0, 7040, 128, 7168),\n",
       " (0, 7168, 128, 7296),\n",
       " (0, 7296, 128, 7424),\n",
       " (0, 7424, 128, 7552),\n",
       " (0, 7552, 128, 7680),\n",
       " (0, 7680, 128, 7808),\n",
       " (0, 7808, 128, 7936),\n",
       " (0, 7936, 128, 8064),\n",
       " (0, 8064, 128, 8192),\n",
       " (0, 8192, 128, 8320),\n",
       " (0, 8320, 128, 8448),\n",
       " (0, 8448, 128, 8576),\n",
       " (0, 8576, 128, 8704),\n",
       " (0, 8704, 128, 8832),\n",
       " (0, 8832, 128, 8960),\n",
       " (0, 8960, 128, 9088),\n",
       " (0, 9088, 128, 9216),\n",
       " (0, 9216, 128, 9344),\n",
       " (0, 9344, 128, 9472),\n",
       " (0, 9472, 128, 9600),\n",
       " (0, 9600, 128, 9728),\n",
       " (0, 9728, 128, 9856),\n",
       " (0, 9856, 128, 9984),\n",
       " (0, 9984, 128, 10112),\n",
       " (0, 10112, 128, 10240),\n",
       " (0, 10240, 128, 10368),\n",
       " (0, 10368, 128, 10496),\n",
       " (0, 10496, 128, 10624),\n",
       " (0, 10624, 128, 10752),\n",
       " (0, 10752, 128, 10880),\n",
       " (0, 10880, 128, 11008),\n",
       " (0, 11008, 128, 11136),\n",
       " (0, 11136, 128, 11264),\n",
       " (0, 11264, 128, 11392),\n",
       " (0, 11392, 128, 11520),\n",
       " (0, 11520, 128, 11648),\n",
       " (0, 11648, 128, 11776),\n",
       " (0, 11776, 128, 11904),\n",
       " (0, 11904, 128, 12032),\n",
       " (0, 12032, 128, 12160),\n",
       " (0, 12160, 128, 12288),\n",
       " (0, 12288, 128, 12416),\n",
       " (0, 12416, 128, 12544),\n",
       " (0, 12544, 128, 12672),\n",
       " (0, 12672, 128, 12800),\n",
       " (0, 12800, 128, 12928),\n",
       " (0, 12928, 128, 13056),\n",
       " (0, 13056, 128, 13184),\n",
       " (0, 13184, 128, 13312),\n",
       " (0, 13312, 128, 13440),\n",
       " (0, 13440, 128, 13568),\n",
       " (0, 13568, 128, 13696),\n",
       " (0, 13696, 128, 13824),\n",
       " (0, 13824, 128, 13952),\n",
       " (0, 13952, 128, 14080),\n",
       " (0, 14080, 128, 14208),\n",
       " (0, 14208, 128, 14336),\n",
       " (0, 14336, 128, 14464),\n",
       " (0, 14464, 128, 14592),\n",
       " (0, 14592, 128, 14720),\n",
       " (0, 14720, 128, 14848),\n",
       " (0, 14848, 128, 14976),\n",
       " (0, 14976, 128, 15104),\n",
       " (0, 15104, 128, 15232),\n",
       " (0, 15232, 128, 15360),\n",
       " (0, 15360, 128, 15488),\n",
       " (0, 15488, 128, 15616),\n",
       " (0, 15616, 128, 15744),\n",
       " (0, 15744, 128, 15872),\n",
       " (0, 15872, 128, 16000),\n",
       " (0, 16000, 128, 16128),\n",
       " (0, 16128, 128, 16256),\n",
       " (0, 16256, 128, 16384),\n",
       " (0, 16384, 128, 16512),\n",
       " (0, 16512, 128, 16640),\n",
       " (0, 16640, 128, 16768),\n",
       " (0, 16768, 128, 16896),\n",
       " (0, 16896, 128, 17024),\n",
       " (0, 17024, 128, 17152),\n",
       " (0, 17152, 128, 17280),\n",
       " (0, 17280, 128, 17408),\n",
       " (0, 17408, 128, 17536),\n",
       " (0, 17536, 128, 17664),\n",
       " (0, 17664, 128, 17792),\n",
       " (0, 17792, 128, 17920),\n",
       " (0, 17920, 128, 18048),\n",
       " (0, 18048, 128, 18176),\n",
       " (0, 18176, 128, 18304),\n",
       " (0, 18304, 128, 18432),\n",
       " (0, 18432, 128, 18560),\n",
       " (0, 18560, 128, 18688),\n",
       " (0, 18688, 128, 18816),\n",
       " (0, 18816, 128, 18944),\n",
       " (0, 18944, 128, 19072),\n",
       " (0, 19072, 128, 19200),\n",
       " (0, 19200, 128, 19328),\n",
       " (0, 19328, 128, 19456),\n",
       " (0, 19456, 128, 19584),\n",
       " (0, 19584, 128, 19712),\n",
       " (0, 19712, 128, 19840),\n",
       " (0, 19840, 128, 19968),\n",
       " (0, 19968, 128, 20096),\n",
       " (0, 20096, 128, 20224),\n",
       " (0, 20224, 128, 20352),\n",
       " (0, 20352, 128, 20480),\n",
       " (0, 20480, 128, 20608),\n",
       " (0, 20608, 128, 20736),\n",
       " (0, 20736, 128, 20864),\n",
       " (0, 20864, 128, 20992),\n",
       " (0, 20992, 128, 21120),\n",
       " (0, 21120, 128, 21248),\n",
       " (0, 21248, 128, 21376),\n",
       " (0, 21376, 128, 21504),\n",
       " (0, 21504, 128, 21632),\n",
       " (0, 21632, 128, 21760),\n",
       " (0, 21760, 128, 21888),\n",
       " (0, 21888, 128, 22016),\n",
       " (0, 22016, 128, 22144),\n",
       " (0, 22144, 128, 22272),\n",
       " (0, 22272, 128, 22400),\n",
       " (0, 22400, 128, 22528),\n",
       " (0, 22528, 128, 22656),\n",
       " (0, 22656, 128, 22784),\n",
       " (0, 22784, 128, 22912),\n",
       " (0, 22912, 128, 23040),\n",
       " (0, 23040, 128, 23168),\n",
       " (0, 23168, 128, 23296),\n",
       " (0, 23296, 128, 23424),\n",
       " (0, 23424, 128, 23552),\n",
       " (0, 23552, 128, 23680),\n",
       " (0, 23680, 128, 23808),\n",
       " (0, 23808, 128, 23936),\n",
       " (0, 23936, 128, 24064),\n",
       " (0, 24064, 128, 24192),\n",
       " (0, 24192, 128, 24320),\n",
       " (0, 24320, 128, 24448),\n",
       " (0, 24448, 128, 24576),\n",
       " (0, 24576, 128, 24704),\n",
       " (0, 24704, 128, 24832),\n",
       " (0, 24832, 128, 24960),\n",
       " (0, 24960, 128, 25088),\n",
       " (0, 25088, 128, 25216),\n",
       " (0, 25216, 128, 25344),\n",
       " (0, 25344, 128, 25472),\n",
       " (0, 25472, 128, 25600),\n",
       " (0, 25600, 128, 25728),\n",
       " (0, 25728, 128, 25856),\n",
       " (0, 25856, 128, 25984),\n",
       " (0, 25984, 128, 26112),\n",
       " (0, 26112, 128, 26240),\n",
       " (0, 26240, 128, 26368),\n",
       " (0, 26368, 128, 26496),\n",
       " (0, 26496, 128, 26624),\n",
       " (0, 26624, 128, 26752),\n",
       " (0, 26752, 128, 26880),\n",
       " (0, 26880, 128, 27008),\n",
       " (0, 27008, 128, 27136),\n",
       " (0, 27136, 128, 27264),\n",
       " (0, 27264, 128, 27392),\n",
       " (0, 27392, 128, 27520),\n",
       " (0, 27520, 128, 27648),\n",
       " (0, 27648, 128, 27776),\n",
       " (0, 27776, 128, 27904),\n",
       " (0, 27904, 128, 28032),\n",
       " (0, 28032, 128, 28160),\n",
       " (0, 28160, 128, 28288),\n",
       " (0, 28288, 128, 28416),\n",
       " (0, 28416, 128, 28544),\n",
       " (0, 28544, 128, 28672),\n",
       " (0, 28672, 128, 28800),\n",
       " (0, 28800, 128, 28928),\n",
       " (0, 28928, 128, 29056),\n",
       " (0, 29056, 128, 29184),\n",
       " (0, 29184, 128, 29312),\n",
       " (0, 29312, 128, 29440),\n",
       " (0, 29440, 128, 29568),\n",
       " (0, 29568, 128, 29696),\n",
       " (0, 29696, 128, 29824),\n",
       " (0, 29824, 128, 29952),\n",
       " (0, 29952, 128, 30080),\n",
       " (0, 30080, 128, 30208),\n",
       " (0, 30208, 128, 30336),\n",
       " (0, 30336, 128, 30464),\n",
       " (0, 30464, 128, 30592),\n",
       " (0, 30592, 128, 30720),\n",
       " (0, 30720, 128, 30848),\n",
       " (0, 30848, 128, 30976),\n",
       " (0, 30976, 128, 31104),\n",
       " (0, 31104, 128, 31232),\n",
       " (0, 31232, 128, 31360),\n",
       " (0, 31360, 128, 31488),\n",
       " (0, 31488, 128, 31616),\n",
       " (0, 31616, 128, 31744),\n",
       " (0, 31744, 128, 31872),\n",
       " (0, 31872, 128, 32000),\n",
       " (0, 32000, 128, 32128),\n",
       " (0, 32128, 128, 32256),\n",
       " (0, 32256, 128, 32384),\n",
       " (0, 32384, 128, 32512),\n",
       " (0, 32512, 128, 32640),\n",
       " (0, 32640, 128, 32768),\n",
       " (0, 32768, 128, 32896),\n",
       " (0, 32896, 128, 33024),\n",
       " (0, 33024, 128, 33152),\n",
       " (0, 33152, 128, 33280),\n",
       " (0, 33280, 128, 33408),\n",
       " (0, 33408, 128, 33536),\n",
       " (0, 33536, 128, 33664),\n",
       " (0, 33664, 128, 33792),\n",
       " (0, 33792, 128, 33920),\n",
       " (0, 33920, 128, 34048),\n",
       " (0, 34048, 128, 34176),\n",
       " (0, 34176, 128, 34304),\n",
       " (0, 34304, 128, 34432),\n",
       " (0, 34432, 128, 34560),\n",
       " (0, 34560, 128, 34688),\n",
       " (0, 34688, 128, 34816),\n",
       " (0, 34816, 128, 34944),\n",
       " (0, 34944, 128, 35072),\n",
       " (0, 35072, 128, 35200),\n",
       " (0, 35200, 128, 35328),\n",
       " (0, 35328, 128, 35456),\n",
       " (0, 35456, 128, 35584),\n",
       " (0, 35584, 128, 35712),\n",
       " (0, 35712, 128, 35840),\n",
       " (0, 35840, 128, 35968),\n",
       " (0, 35968, 128, 36096),\n",
       " (0, 36096, 128, 36224),\n",
       " (0, 36224, 128, 36352),\n",
       " (0, 36352, 128, 36480),\n",
       " (0, 36480, 128, 36608),\n",
       " (0, 36608, 128, 36736),\n",
       " (0, 36736, 128, 36864),\n",
       " (0, 36864, 128, 36992),\n",
       " (0, 36992, 128, 37120),\n",
       " (0, 37120, 128, 37248),\n",
       " (0, 37248, 128, 37376),\n",
       " (0, 37376, 128, 37504),\n",
       " (0, 37504, 128, 37632),\n",
       " (0, 37632, 128, 37760),\n",
       " (0, 37760, 128, 37888),\n",
       " (0, 37888, 128, 38016),\n",
       " (0, 38016, 128, 38144),\n",
       " (0, 38144, 128, 38272),\n",
       " (0, 38272, 128, 38400),\n",
       " (0, 38400, 128, 38528),\n",
       " (0, 38528, 128, 38656),\n",
       " (0, 38656, 128, 38784),\n",
       " (0, 38784, 128, 38912),\n",
       " (0, 38912, 128, 39040),\n",
       " (0, 39040, 128, 39168),\n",
       " (0, 39168, 128, 39296),\n",
       " (0, 39296, 128, 39424),\n",
       " (0, 39424, 128, 39552),\n",
       " (0, 39552, 128, 39680),\n",
       " (0, 39680, 128, 39808),\n",
       " (0, 39808, 128, 39936),\n",
       " (0, 39936, 128, 40064),\n",
       " (0, 40064, 128, 40192),\n",
       " (0, 40192, 128, 40320),\n",
       " (0, 40320, 128, 40448),\n",
       " (0, 40448, 128, 40576),\n",
       " (0, 40576, 128, 40704),\n",
       " (0, 40704, 128, 40832),\n",
       " (0, 40832, 128, 40960),\n",
       " (0, 40960, 128, 41088),\n",
       " (0, 41088, 128, 41216),\n",
       " (0, 41216, 128, 41344),\n",
       " (0, 41344, 128, 41472),\n",
       " (0, 41472, 128, 41600),\n",
       " (0, 41600, 128, 41728),\n",
       " (0, 41728, 128, 41856),\n",
       " (0, 41856, 128, 41984),\n",
       " (0, 41984, 128, 42112),\n",
       " (0, 42112, 128, 42240),\n",
       " (0, 42240, 128, 42368),\n",
       " (0, 42368, 128, 42496),\n",
       " (0, 42496, 128, 42624),\n",
       " (0, 42624, 128, 42752),\n",
       " (0, 42752, 128, 42880),\n",
       " (0, 42880, 128, 43008),\n",
       " (0, 43008, 128, 43136),\n",
       " (0, 43136, 128, 43264),\n",
       " (0, 43264, 128, 43392),\n",
       " (0, 43392, 128, 43520),\n",
       " (0, 43520, 128, 43648),\n",
       " (0, 43648, 128, 43776),\n",
       " (0, 43776, 128, 43904),\n",
       " (0, 43904, 128, 44032),\n",
       " (0, 44032, 128, 44160),\n",
       " (0, 44160, 128, 44288),\n",
       " (0, 44288, 128, 44416),\n",
       " (0, 44416, 128, 44544),\n",
       " (0, 44544, 128, 44672),\n",
       " (0, 44672, 128, 44800),\n",
       " (0, 44800, 128, 44928),\n",
       " (0, 44928, 128, 45056),\n",
       " (0, 45056, 128, 45184),\n",
       " (0, 45184, 128, 45312),\n",
       " (0, 45312, 128, 45440),\n",
       " (0, 45440, 128, 45568),\n",
       " (0, 45568, 128, 45696),\n",
       " (0, 45696, 128, 45824),\n",
       " (0, 45824, 128, 45952),\n",
       " (0, 45952, 128, 46080),\n",
       " (0, 46080, 128, 46208),\n",
       " (0, 46208, 128, 46336),\n",
       " (0, 46336, 128, 46464),\n",
       " (0, 46464, 128, 46592),\n",
       " (0, 46592, 128, 46720),\n",
       " (0, 46720, 128, 46848),\n",
       " (0, 46848, 128, 46976),\n",
       " (0, 46976, 128, 47104),\n",
       " (0, 47104, 128, 47232),\n",
       " (0, 47232, 128, 47360),\n",
       " (0, 47360, 128, 47488),\n",
       " (0, 47488, 128, 47616),\n",
       " (0, 47616, 128, 47744),\n",
       " (0, 47744, 128, 47872),\n",
       " (0, 47872, 128, 48000),\n",
       " (0, 48000, 128, 48128),\n",
       " (0, 48128, 128, 48256),\n",
       " (0, 48256, 128, 48384),\n",
       " (0, 48384, 128, 48512),\n",
       " (0, 48512, 128, 48640),\n",
       " (0, 48640, 128, 48768),\n",
       " (0, 48768, 128, 48896),\n",
       " (0, 48896, 128, 49024),\n",
       " (0, 49024, 128, 49152),\n",
       " (0, 49152, 128, 49280),\n",
       " (0, 49280, 128, 49408),\n",
       " (0, 49408, 128, 49536),\n",
       " (0, 49536, 128, 49664),\n",
       " (0, 49664, 128, 49792),\n",
       " (0, 49792, 128, 49920),\n",
       " (0, 49920, 128, 50048),\n",
       " (0, 50048, 128, 50176),\n",
       " (0, 50176, 128, 50304),\n",
       " (0, 50304, 128, 50432),\n",
       " (0, 50432, 128, 50560),\n",
       " (0, 50560, 128, 50688),\n",
       " (0, 50688, 128, 50816),\n",
       " (0, 50816, 128, 50944),\n",
       " (0, 50944, 128, 51072),\n",
       " (0, 51072, 128, 51200),\n",
       " (0, 51200, 128, 51328),\n",
       " (0, 51328, 128, 51456),\n",
       " (0, 51456, 128, 51584),\n",
       " (0, 51584, 128, 51712),\n",
       " (0, 51712, 128, 51840),\n",
       " (0, 51840, 128, 51968),\n",
       " (0, 51968, 128, 52096),\n",
       " (0, 52096, 128, 52224),\n",
       " (0, 52224, 128, 52352),\n",
       " (0, 52352, 128, 52480),\n",
       " (0, 52480, 128, 52608),\n",
       " (0, 52608, 128, 52736),\n",
       " (0, 52736, 128, 52864),\n",
       " (0, 52864, 128, 52992),\n",
       " (0, 52992, 128, 53120),\n",
       " (0, 53120, 128, 53248),\n",
       " (0, 53248, 128, 53376),\n",
       " (0, 53376, 128, 53504),\n",
       " (0, 53504, 128, 53632),\n",
       " (0, 53632, 128, 53760),\n",
       " (0, 53760, 128, 53888),\n",
       " (0, 53888, 128, 54016),\n",
       " (0, 54016, 128, 54144),\n",
       " (0, 54144, 128, 54272),\n",
       " (0, 54272, 128, 54400),\n",
       " (0, 54400, 128, 54528),\n",
       " (0, 54528, 128, 54656),\n",
       " (0, 54656, 128, 54784),\n",
       " (0, 54784, 128, 54912),\n",
       " (0, 54912, 128, 55040),\n",
       " (0, 55040, 128, 55168),\n",
       " (0, 55168, 128, 55296),\n",
       " (0, 55296, 128, 55424),\n",
       " (0, 55424, 128, 55552),\n",
       " (0, 55552, 128, 55680),\n",
       " (0, 55680, 128, 55808),\n",
       " (0, 55808, 128, 55936),\n",
       " (0, 55936, 128, 56064),\n",
       " (0, 56064, 128, 56192),\n",
       " (0, 56192, 128, 56320),\n",
       " (0, 56320, 128, 56448),\n",
       " (0, 56448, 128, 56576),\n",
       " (0, 56576, 128, 56704),\n",
       " (0, 56704, 128, 56832),\n",
       " (0, 56832, 128, 56960),\n",
       " (0, 56960, 128, 57088),\n",
       " (0, 57088, 128, 57216),\n",
       " (0, 57216, 128, 57344),\n",
       " (0, 57344, 128, 57472),\n",
       " (0, 57472, 128, 57600),\n",
       " (0, 57600, 128, 57728),\n",
       " (0, 57728, 128, 57856),\n",
       " (0, 57856, 128, 57984),\n",
       " (0, 57984, 128, 58112),\n",
       " (0, 58112, 128, 58240),\n",
       " (0, 58240, 128, 58368),\n",
       " (0, 58368, 128, 58496),\n",
       " (0, 58496, 128, 58624),\n",
       " (0, 58624, 128, 58752),\n",
       " (0, 58752, 128, 58880),\n",
       " (0, 58880, 128, 59008),\n",
       " (0, 59008, 128, 59136),\n",
       " (0, 59136, 128, 59264),\n",
       " (0, 59264, 128, 59392),\n",
       " (0, 59392, 128, 59520),\n",
       " (0, 59520, 128, 59648),\n",
       " (0, 59648, 128, 59776),\n",
       " (0, 59776, 128, 59904),\n",
       " (0, 59904, 128, 60032),\n",
       " (0, 60032, 128, 60160),\n",
       " (0, 60160, 128, 60288),\n",
       " (0, 60288, 128, 60416),\n",
       " (0, 60416, 128, 60544),\n",
       " (0, 60544, 128, 60672),\n",
       " (0, 60672, 128, 60800),\n",
       " (0, 60800, 128, 60928),\n",
       " (0, 60928, 128, 61056),\n",
       " (0, 61056, 128, 61184),\n",
       " (0, 61184, 128, 61312),\n",
       " (0, 61312, 128, 61440),\n",
       " (0, 61440, 128, 61568),\n",
       " (0, 61568, 128, 61696),\n",
       " (0, 61696, 128, 61824),\n",
       " (0, 61824, 128, 61952),\n",
       " (0, 61952, 128, 62080),\n",
       " (0, 62080, 128, 62208),\n",
       " (0, 62208, 128, 62336),\n",
       " (0, 62336, 128, 62464),\n",
       " (0, 62464, 128, 62592),\n",
       " (0, 62592, 128, 62720),\n",
       " (0, 62720, 128, 62848),\n",
       " (0, 62848, 128, 62976),\n",
       " (0, 62976, 128, 63104),\n",
       " (0, 63104, 128, 63232),\n",
       " (0, 63232, 128, 63360),\n",
       " (0, 63360, 128, 63488),\n",
       " (0, 63488, 128, 63616),\n",
       " (0, 63616, 128, 63744),\n",
       " (0, 63744, 128, 63872),\n",
       " (0, 63872, 128, 64000),\n",
       " (0, 64000, 128, 64128),\n",
       " (0, 64128, 128, 64256),\n",
       " (0, 64256, 128, 64384),\n",
       " (0, 64384, 128, 64512),\n",
       " (0, 64512, 128, 64640),\n",
       " (0, 64640, 128, 64768),\n",
       " (0, 64768, 128, 64896),\n",
       " (0, 64896, 128, 65024),\n",
       " (0, 65024, 128, 65152),\n",
       " (0, 65152, 128, 65280),\n",
       " (0, 65280, 128, 65408),\n",
       " (0, 65408, 128, 65536),\n",
       " (0, 65536, 128, 65664),\n",
       " (0, 65664, 128, 65792),\n",
       " (0, 65792, 128, 65920),\n",
       " (0, 65920, 128, 66048),\n",
       " (0, 66048, 128, 66176),\n",
       " (0, 66176, 128, 66304),\n",
       " (0, 66304, 128, 66432),\n",
       " (0, 66432, 128, 66560),\n",
       " (0, 66560, 128, 66688),\n",
       " (0, 66688, 128, 66816),\n",
       " (0, 66816, 128, 66944),\n",
       " (0, 66944, 128, 67072),\n",
       " (0, 67072, 128, 67200),\n",
       " (0, 67200, 128, 67328),\n",
       " (0, 67328, 128, 67456),\n",
       " (0, 67456, 128, 67584),\n",
       " (0, 67584, 128, 67712),\n",
       " (0, 67712, 128, 67840),\n",
       " (0, 67840, 128, 67968),\n",
       " (0, 67968, 128, 68096),\n",
       " (0, 68096, 128, 68224),\n",
       " (0, 68224, 128, 68352),\n",
       " (0, 68352, 128, 68480),\n",
       " (0, 68480, 128, 68608),\n",
       " (0, 68608, 128, 68736),\n",
       " (0, 68736, 128, 68864),\n",
       " (0, 68864, 128, 68992),\n",
       " (0, 68992, 128, 69120),\n",
       " (0, 69120, 128, 69248),\n",
       " (0, 69248, 128, 69376),\n",
       " (0, 69376, 128, 69504),\n",
       " (0, 69504, 128, 69632),\n",
       " (0, 69632, 128, 69760),\n",
       " (0, 69760, 128, 69888),\n",
       " (0, 69888, 128, 70016),\n",
       " (0, 70016, 128, 70144),\n",
       " (0, 70144, 128, 70272),\n",
       " (0, 70272, 128, 70400),\n",
       " (0, 70400, 128, 70528),\n",
       " (0, 70528, 128, 70656),\n",
       " (0, 70656, 128, 70784),\n",
       " (0, 70784, 128, 70912),\n",
       " (0, 70912, 128, 71040),\n",
       " (0, 71040, 128, 71168),\n",
       " (0, 71168, 128, 71296),\n",
       " (0, 71296, 128, 71424),\n",
       " (0, 71424, 128, 71552),\n",
       " (0, 71552, 128, 71680),\n",
       " (0, 71680, 128, 71808),\n",
       " (0, 71808, 128, 71936),\n",
       " (0, 71936, 128, 72064),\n",
       " (0, 72064, 128, 72192),\n",
       " (0, 72192, 128, 72320),\n",
       " (0, 72320, 128, 72448),\n",
       " (0, 72448, 128, 72576),\n",
       " (0, 72576, 128, 72704),\n",
       " (0, 72704, 128, 72832),\n",
       " (0, 72832, 128, 72960),\n",
       " (0, 72960, 128, 73088),\n",
       " (0, 73088, 128, 73216),\n",
       " (0, 73216, 128, 73344),\n",
       " (0, 73344, 128, 73472),\n",
       " (0, 73472, 128, 73600),\n",
       " (0, 73600, 128, 73728),\n",
       " (0, 73728, 128, 73856),\n",
       " (0, 73856, 128, 73984),\n",
       " (0, 73984, 128, 74112),\n",
       " (0, 74112, 128, 74240),\n",
       " (0, 74240, 128, 74368),\n",
       " (0, 74368, 128, 74496),\n",
       " (0, 74496, 128, 74624),\n",
       " (0, 74624, 128, 74752),\n",
       " (0, 74752, 128, 74880),\n",
       " (0, 74880, 128, 75008),\n",
       " (0, 75008, 128, 75136),\n",
       " (0, 75136, 128, 75264),\n",
       " (0, 75264, 128, 75392),\n",
       " (0, 75392, 128, 75520),\n",
       " (0, 75520, 128, 75648),\n",
       " (0, 75648, 128, 75776),\n",
       " (0, 75776, 128, 75904),\n",
       " (0, 75904, 128, 76032),\n",
       " (0, 76032, 128, 76160),\n",
       " (0, 76160, 128, 76288),\n",
       " (0, 76288, 128, 76416),\n",
       " (0, 76416, 128, 76544),\n",
       " (0, 76544, 128, 76672),\n",
       " (0, 76672, 128, 76800),\n",
       " (0, 76800, 128, 76928),\n",
       " (0, 76928, 128, 77056),\n",
       " (0, 77056, 128, 77184),\n",
       " (0, 77184, 128, 77312),\n",
       " (0, 77312, 128, 77440),\n",
       " (0, 77440, 128, 77568),\n",
       " (0, 77568, 128, 77696),\n",
       " (0, 77696, 128, 77824),\n",
       " (0, 77824, 128, 77952),\n",
       " (0, 77952, 128, 78080),\n",
       " (0, 78080, 128, 78208),\n",
       " (0, 78208, 128, 78336),\n",
       " (0, 78336, 128, 78464),\n",
       " (0, 78464, 128, 78592),\n",
       " (0, 78592, 128, 78720),\n",
       " (0, 78720, 128, 78848),\n",
       " (0, 78848, 128, 78976),\n",
       " (0, 78976, 128, 79104),\n",
       " (0, 79104, 128, 79232),\n",
       " (0, 79232, 128, 79360),\n",
       " (0, 79360, 128, 79488),\n",
       " (0, 79488, 128, 79616),\n",
       " (0, 79616, 128, 79744),\n",
       " (0, 79744, 128, 79872),\n",
       " (0, 79872, 128, 80000),\n",
       " (0, 80000, 128, 80128),\n",
       " (0, 80128, 128, 80256),\n",
       " (0, 80256, 128, 80384),\n",
       " (0, 80384, 128, 80512),\n",
       " (0, 80512, 128, 80640),\n",
       " (0, 80640, 128, 80768),\n",
       " (0, 80768, 128, 80896),\n",
       " (0, 80896, 128, 81024),\n",
       " (0, 81024, 128, 81152),\n",
       " (0, 81152, 128, 81280),\n",
       " (0, 81280, 128, 81408),\n",
       " (0, 81408, 128, 81536),\n",
       " (0, 81536, 128, 81664),\n",
       " (0, 81664, 128, 81792),\n",
       " (0, 81792, 128, 81920),\n",
       " (0, 81920, 128, 82048),\n",
       " (0, 82048, 128, 82176),\n",
       " (0, 82176, 128, 82304),\n",
       " (0, 82304, 128, 82432),\n",
       " (0, 82432, 128, 82560),\n",
       " (0, 82560, 128, 82688),\n",
       " (0, 82688, 128, 82816),\n",
       " (0, 82816, 128, 82944),\n",
       " (0, 82944, 128, 83072),\n",
       " (0, 83072, 128, 83200),\n",
       " (0, 83200, 128, 83328),\n",
       " (0, 83328, 128, 83456),\n",
       " (0, 83456, 128, 83584),\n",
       " (0, 83584, 128, 83712),\n",
       " (0, 83712, 128, 83840),\n",
       " (0, 83840, 128, 83968),\n",
       " (0, 83968, 128, 84096),\n",
       " (0, 84096, 128, 84224),\n",
       " (0, 84224, 128, 84352),\n",
       " (0, 84352, 128, 84480),\n",
       " (0, 84480, 128, 84608),\n",
       " (0, 84608, 128, 84736),\n",
       " (0, 84736, 128, 84864),\n",
       " (0, 84864, 128, 84992),\n",
       " (0, 84992, 128, 85120),\n",
       " (0, 85120, 128, 85248),\n",
       " (0, 85248, 128, 85376),\n",
       " (0, 85376, 128, 85504),\n",
       " (0, 85504, 128, 85632),\n",
       " (0, 85632, 128, 85760),\n",
       " (0, 85760, 128, 85888),\n",
       " (0, 85888, 128, 86016),\n",
       " (0, 86016, 128, 86144),\n",
       " (0, 86144, 128, 86272),\n",
       " (0, 86272, 128, 86400),\n",
       " (0, 86400, 128, 86528),\n",
       " (0, 86528, 128, 86656),\n",
       " (0, 86656, 128, 86784),\n",
       " (0, 86784, 128, 86912),\n",
       " (0, 86912, 128, 87040),\n",
       " (0, 87040, 128, 87168),\n",
       " (0, 87168, 128, 87296),\n",
       " (0, 87296, 128, 87424),\n",
       " (0, 87424, 128, 87552),\n",
       " (0, 87552, 128, 87680),\n",
       " (0, 87680, 128, 87808),\n",
       " (0, 87808, 128, 87936),\n",
       " (0, 87936, 128, 88064),\n",
       " (0, 88064, 128, 88192),\n",
       " (0, 88192, 128, 88320),\n",
       " (0, 88320, 128, 88448),\n",
       " (0, 88448, 128, 88576),\n",
       " (0, 88576, 128, 88704),\n",
       " (0, 88704, 128, 88832),\n",
       " (0, 88832, 128, 88960),\n",
       " (0, 88960, 128, 89088),\n",
       " (0, 89088, 128, 89216),\n",
       " (0, 89216, 128, 89344),\n",
       " (0, 89344, 128, 89472),\n",
       " (0, 89472, 128, 89600),\n",
       " (0, 89600, 128, 89728),\n",
       " (0, 89728, 128, 89856),\n",
       " (0, 89856, 128, 89984),\n",
       " (0, 89984, 128, 90112),\n",
       " (0, 90112, 128, 90240),\n",
       " (0, 90240, 128, 90368),\n",
       " (0, 90368, 128, 90496),\n",
       " (0, 90496, 128, 90624),\n",
       " (0, 90624, 128, 90752),\n",
       " (0, 90752, 128, 90880),\n",
       " (0, 90880, 128, 91008),\n",
       " (0, 91008, 128, 91136),\n",
       " (0, 91136, 128, 91264),\n",
       " (0, 91264, 128, 91392),\n",
       " (0, 91392, 128, 91520),\n",
       " (0, 91520, 128, 91648),\n",
       " (0, 91648, 128, 91776),\n",
       " (0, 91776, 128, 91904),\n",
       " (0, 91904, 128, 92032),\n",
       " (0, 92032, 128, 92160),\n",
       " (0, 92160, 128, 92288),\n",
       " (0, 92288, 128, 92416),\n",
       " (0, 92416, 128, 92544),\n",
       " (0, 92544, 128, 92672),\n",
       " (0, 92672, 128, 92800),\n",
       " (0, 92800, 128, 92928),\n",
       " (0, 92928, 128, 93056),\n",
       " (0, 93056, 128, 93184),\n",
       " (0, 93184, 128, 93312),\n",
       " (0, 93312, 128, 93440),\n",
       " (0, 93440, 128, 93568),\n",
       " (0, 93568, 128, 93696),\n",
       " (0, 93696, 128, 93824),\n",
       " (0, 93824, 128, 93952),\n",
       " (0, 93952, 128, 94080),\n",
       " (0, 94080, 128, 94208),\n",
       " (0, 94208, 128, 94336),\n",
       " (0, 94336, 128, 94464),\n",
       " (0, 94464, 128, 94592),\n",
       " (0, 94592, 128, 94720),\n",
       " (0, 94720, 128, 94848),\n",
       " (0, 94848, 128, 94976),\n",
       " (0, 94976, 128, 95104),\n",
       " (0, 95104, 128, 95232),\n",
       " (0, 95232, 128, 95360),\n",
       " (0, 95360, 128, 95488),\n",
       " (0, 95488, 128, 95616),\n",
       " (0, 95616, 128, 95744),\n",
       " (0, 95744, 128, 95872),\n",
       " (0, 95872, 128, 96000),\n",
       " (0, 96000, 128, 96128),\n",
       " (0, 96128, 128, 96256),\n",
       " (0, 96256, 128, 96384),\n",
       " (0, 96384, 128, 96512),\n",
       " (0, 96512, 128, 96640),\n",
       " (0, 96640, 128, 96768),\n",
       " (0, 96768, 128, 96896),\n",
       " (0, 96896, 128, 97024),\n",
       " (0, 97024, 128, 97152),\n",
       " (0, 97152, 128, 97280),\n",
       " (0, 97280, 128, 97408),\n",
       " (0, 97408, 128, 97536),\n",
       " (0, 97536, 128, 97664),\n",
       " (0, 97664, 128, 97792),\n",
       " (0, 97792, 128, 97920),\n",
       " (0, 97920, 128, 98048),\n",
       " (0, 98048, 128, 98176),\n",
       " (0, 98176, 128, 98304),\n",
       " (0, 98304, 128, 98432),\n",
       " (0, 98432, 128, 98560),\n",
       " (0, 98560, 128, 98688),\n",
       " (0, 98688, 128, 98816),\n",
       " (0, 98816, 128, 98944),\n",
       " (0, 98944, 128, 99072),\n",
       " (0, 99072, 128, 99200),\n",
       " (0, 99200, 128, 99328),\n",
       " (0, 99328, 128, 99456),\n",
       " (0, 99456, 128, 99584),\n",
       " (0, 99584, 128, 99712),\n",
       " (0, 99712, 128, 99840),\n",
       " (0, 99840, 128, 99968),\n",
       " (0, 99968, 128, 100096),\n",
       " (0, 100096, 128, 100224),\n",
       " (0, 100224, 128, 100352),\n",
       " (0, 100352, 128, 100480),\n",
       " (0, 100480, 128, 100608),\n",
       " (0, 100608, 128, 100736),\n",
       " (0, 100736, 128, 100864),\n",
       " (0, 100864, 128, 100992),\n",
       " (0, 100992, 128, 101120),\n",
       " (0, 101120, 128, 101248),\n",
       " (0, 101248, 128, 101376),\n",
       " (0, 101376, 128, 101504),\n",
       " (0, 101504, 128, 101632),\n",
       " (0, 101632, 128, 101760),\n",
       " (0, 101760, 128, 101888),\n",
       " (0, 101888, 128, 102016),\n",
       " (0, 102016, 128, 102144),\n",
       " (0, 102144, 128, 102272),\n",
       " (0, 102272, 128, 102400),\n",
       " (0, 102400, 128, 102528),\n",
       " (0, 102528, 128, 102656),\n",
       " (0, 102656, 128, 102784),\n",
       " (0, 102784, 128, 102912),\n",
       " (0, 102912, 128, 103040),\n",
       " (0, 103040, 128, 103168),\n",
       " (0, 103168, 128, 103296),\n",
       " (0, 103296, 128, 103424),\n",
       " (0, 103424, 128, 103552),\n",
       " (0, 103552, 128, 103680),\n",
       " (0, 103680, 128, 103808),\n",
       " (0, 103808, 128, 103936),\n",
       " (0, 103936, 128, 104064),\n",
       " (0, 104064, 128, 104192),\n",
       " (0, 104192, 128, 104320),\n",
       " (0, 104320, 128, 104448),\n",
       " (0, 104448, 128, 104576),\n",
       " (0, 104576, 128, 104704),\n",
       " (0, 104704, 128, 104832),\n",
       " (0, 104832, 128, 104960),\n",
       " (0, 104960, 128, 105088),\n",
       " (0, 105088, 128, 105216),\n",
       " (0, 105216, 128, 105344),\n",
       " (0, 105344, 128, 105472),\n",
       " (0, 105472, 128, 105600),\n",
       " (0, 105600, 128, 105728),\n",
       " (0, 105728, 128, 105856),\n",
       " (0, 105856, 128, 105984),\n",
       " (0, 105984, 128, 106112),\n",
       " (0, 106112, 128, 106240),\n",
       " (0, 106240, 128, 106368),\n",
       " (0, 106368, 128, 106496),\n",
       " (0, 106496, 128, 106624),\n",
       " (0, 106624, 128, 106752),\n",
       " (0, 106752, 128, 106880),\n",
       " (0, 106880, 128, 107008),\n",
       " (0, 107008, 128, 107136),\n",
       " (0, 107136, 128, 107264),\n",
       " (0, 107264, 128, 107392),\n",
       " (0, 107392, 128, 107520),\n",
       " (0, 107520, 128, 107648),\n",
       " (0, 107648, 128, 107776),\n",
       " (0, 107776, 128, 107904),\n",
       " (0, 107904, 128, 108032),\n",
       " (0, 108032, 128, 108160),\n",
       " (0, 108160, 128, 108288),\n",
       " (0, 108288, 128, 108416),\n",
       " (0, 108416, 128, 108544),\n",
       " (0, 108544, 128, 108672),\n",
       " (0, 108672, 128, 108800),\n",
       " (0, 108800, 128, 108928),\n",
       " (0, 108928, 128, 109056),\n",
       " (0, 109056, 128, 109184),\n",
       " (0, 109184, 128, 109312),\n",
       " (0, 109312, 128, 109440),\n",
       " (0, 109440, 128, 109568),\n",
       " (0, 109568, 128, 109696),\n",
       " (0, 109696, 128, 109824),\n",
       " (0, 109824, 128, 109952),\n",
       " (0, 109952, 128, 110080),\n",
       " (0, 110080, 128, 110208),\n",
       " (0, 110208, 128, 110336),\n",
       " (0, 110336, 128, 110464),\n",
       " (0, 110464, 128, 110592),\n",
       " (0, 110592, 128, 110720),\n",
       " (0, 110720, 128, 110848),\n",
       " (0, 110848, 128, 110976),\n",
       " (0, 110976, 128, 111104),\n",
       " (0, 111104, 128, 111232),\n",
       " (0, 111232, 128, 111360),\n",
       " (0, 111360, 128, 111488),\n",
       " (0, 111488, 128, 111616),\n",
       " (0, 111616, 128, 111744),\n",
       " (0, 111744, 128, 111872),\n",
       " (0, 111872, 128, 112000),\n",
       " (0, 112000, 128, 112128),\n",
       " (0, 112128, 128, 112256),\n",
       " (0, 112256, 128, 112384),\n",
       " (0, 112384, 128, 112512),\n",
       " (0, 112512, 128, 112640),\n",
       " (0, 112640, 128, 112768),\n",
       " (0, 112768, 128, 112896),\n",
       " (0, 112896, 128, 113024),\n",
       " (0, 113024, 128, 113152),\n",
       " (0, 113152, 128, 113280),\n",
       " (0, 113280, 128, 113408),\n",
       " (0, 113408, 128, 113536),\n",
       " (0, 113536, 128, 113664),\n",
       " (0, 113664, 128, 113792),\n",
       " (0, 113792, 128, 113920),\n",
       " (0, 113920, 128, 114048),\n",
       " (0, 114048, 128, 114176),\n",
       " (0, 114176, 128, 114304),\n",
       " (0, 114304, 128, 114432),\n",
       " (0, 114432, 128, 114560),\n",
       " (0, 114560, 128, 114688),\n",
       " (0, 114688, 128, 114816),\n",
       " (0, 114816, 128, 114944),\n",
       " (0, 114944, 128, 115072),\n",
       " (0, 115072, 128, 115200),\n",
       " (0, 115200, 128, 115328),\n",
       " (0, 115328, 128, 115456),\n",
       " (0, 115456, 128, 115584),\n",
       " (0, 115584, 128, 115712),\n",
       " (0, 115712, 128, 115840),\n",
       " (0, 115840, 128, 115968),\n",
       " (0, 115968, 128, 116096),\n",
       " (0, 116096, 128, 116224),\n",
       " (0, 116224, 128, 116352),\n",
       " (0, 116352, 128, 116480),\n",
       " (0, 116480, 128, 116608),\n",
       " (0, 116608, 128, 116736),\n",
       " (0, 116736, 128, 116864),\n",
       " (0, 116864, 128, 116992),\n",
       " (0, 116992, 128, 117120),\n",
       " (0, 117120, 128, 117248),\n",
       " (0, 117248, 128, 117376),\n",
       " (0, 117376, 128, 117504),\n",
       " (0, 117504, 128, 117632),\n",
       " (0, 117632, 128, 117760),\n",
       " (0, 117760, 128, 117888),\n",
       " (0, 117888, 128, 118016),\n",
       " (0, 118016, 128, 118144),\n",
       " (0, 118144, 128, 118272),\n",
       " (0, 118272, 128, 118400),\n",
       " (0, 118400, 128, 118528),\n",
       " (0, 118528, 128, 118656),\n",
       " (0, 118656, 128, 118784),\n",
       " (0, 118784, 128, 118912),\n",
       " (0, 118912, 128, 119040),\n",
       " (0, 119040, 128, 119168),\n",
       " (0, 119168, 128, 119296),\n",
       " (0, 119296, 128, 119424),\n",
       " (0, 119424, 128, 119552),\n",
       " (0, 119552, 128, 119680),\n",
       " (0, 119680, 128, 119808),\n",
       " (0, 119808, 128, 119936),\n",
       " (0, 119936, 128, 120064),\n",
       " (0, 120064, 128, 120192),\n",
       " (0, 120192, 128, 120320),\n",
       " (0, 120320, 128, 120448),\n",
       " (0, 120448, 128, 120576),\n",
       " (0, 120576, 128, 120704),\n",
       " (0, 120704, 128, 120832),\n",
       " (0, 120832, 128, 120960),\n",
       " (0, 120960, 128, 121088),\n",
       " (0, 121088, 128, 121216),\n",
       " (0, 121216, 128, 121344),\n",
       " (0, 121344, 128, 121472),\n",
       " (0, 121472, 128, 121600),\n",
       " (0, 121600, 128, 121728),\n",
       " (0, 121728, 128, 121856),\n",
       " (0, 121856, 128, 121984),\n",
       " (0, 121984, 128, 122112),\n",
       " (0, 122112, 128, 122240),\n",
       " (0, 122240, 128, 122368),\n",
       " (0, 122368, 128, 122496),\n",
       " (0, 122496, 128, 122624),\n",
       " (0, 122624, 128, 122752),\n",
       " (0, 122752, 128, 122880),\n",
       " (0, 122880, 128, 123008),\n",
       " (0, 123008, 128, 123136),\n",
       " (0, 123136, 128, 123264),\n",
       " (0, 123264, 128, 123392),\n",
       " (0, 123392, 128, 123520),\n",
       " (0, 123520, 128, 123648),\n",
       " (0, 123648, 128, 123776),\n",
       " (0, 123776, 128, 123904),\n",
       " (0, 123904, 128, 124032),\n",
       " (0, 124032, 128, 124160),\n",
       " (0, 124160, 128, 124288),\n",
       " (0, 124288, 128, 124416),\n",
       " (0, 124416, 128, 124544),\n",
       " (0, 124544, 128, 124672),\n",
       " (0, 124672, 128, 124800),\n",
       " (0, 124800, 128, 124928),\n",
       " (0, 124928, 128, 125056),\n",
       " (0, 125056, 128, 125184),\n",
       " (0, 125184, 128, 125312),\n",
       " (0, 125312, 128, 125440),\n",
       " (0, 125440, 128, 125568),\n",
       " (0, 125568, 128, 125696),\n",
       " (0, 125696, 128, 125824),\n",
       " (0, 125824, 128, 125952),\n",
       " (0, 125952, 128, 126080),\n",
       " (0, 126080, 128, 126208),\n",
       " (0, 126208, 128, 126336),\n",
       " (0, 126336, 128, 126464),\n",
       " (0, 126464, 128, 126592),\n",
       " (0, 126592, 128, 126720),\n",
       " (0, 126720, 128, 126848),\n",
       " (0, 126848, 128, 126976),\n",
       " (0, 126976, 128, 127104),\n",
       " (0, 127104, 128, 127232),\n",
       " (0, 127232, 128, 127360),\n",
       " (0, 127360, 128, 127488),\n",
       " (0, 127488, 128, 127616),\n",
       " (0, 127616, 128, 127744),\n",
       " (0, 127744, 128, 127872),\n",
       " (0, 127872, 128, 128000),\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610c60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling samples / перемешивание тайлов\n",
    "samples = list(range(len(tiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c1b2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39835,\n",
       " 426550,\n",
       " 181911,\n",
       " 523918,\n",
       " 488131,\n",
       " 623641,\n",
       " 486702,\n",
       " 119430,\n",
       " 399948,\n",
       " 102815,\n",
       " 287068,\n",
       " 149306,\n",
       " 213356,\n",
       " 439911,\n",
       " 467365,\n",
       " 500018,\n",
       " 127822,\n",
       " 517009,\n",
       " 309426,\n",
       " 53235,\n",
       " 132422,\n",
       " 398907,\n",
       " 241276,\n",
       " 556842,\n",
       " 445047,\n",
       " 92312,\n",
       " 555997,\n",
       " 197758,\n",
       " 213660,\n",
       " 635660,\n",
       " 326046,\n",
       " 472495,\n",
       " 141066,\n",
       " 419357,\n",
       " 398797,\n",
       " 562182,\n",
       " 433605,\n",
       " 38414,\n",
       " 508973,\n",
       " 419171,\n",
       " 14484,\n",
       " 384330,\n",
       " 542195,\n",
       " 538670,\n",
       " 70437,\n",
       " 539147,\n",
       " 375822,\n",
       " 658917,\n",
       " 382712,\n",
       " 57240,\n",
       " 85812,\n",
       " 9050,\n",
       " 60179,\n",
       " 230579,\n",
       " 391133,\n",
       " 677658,\n",
       " 117911,\n",
       " 114601,\n",
       " 157164,\n",
       " 118836,\n",
       " 56161,\n",
       " 590190,\n",
       " 128775,\n",
       " 84756,\n",
       " 571050,\n",
       " 340052,\n",
       " 299968,\n",
       " 576363,\n",
       " 621205,\n",
       " 352035,\n",
       " 172891,\n",
       " 452411,\n",
       " 395769,\n",
       " 610073,\n",
       " 383245,\n",
       " 546980,\n",
       " 551739,\n",
       " 115822,\n",
       " 479245,\n",
       " 285077,\n",
       " 376648,\n",
       " 669662,\n",
       " 76927,\n",
       " 512250,\n",
       " 334901,\n",
       " 33281,\n",
       " 58962,\n",
       " 204392,\n",
       " 651473,\n",
       " 272610,\n",
       " 336997,\n",
       " 573293,\n",
       " 314586,\n",
       " 247632,\n",
       " 97359,\n",
       " 52936,\n",
       " 680685,\n",
       " 241736,\n",
       " 354126,\n",
       " 414547,\n",
       " 264241,\n",
       " 211309,\n",
       " 516658,\n",
       " 93563,\n",
       " 579361,\n",
       " 31297,\n",
       " 638802,\n",
       " 518128,\n",
       " 563793,\n",
       " 48554,\n",
       " 369623,\n",
       " 241225,\n",
       " 7199,\n",
       " 169222,\n",
       " 588402,\n",
       " 473293,\n",
       " 297436,\n",
       " 193103,\n",
       " 4137,\n",
       " 542869,\n",
       " 390365,\n",
       " 345022,\n",
       " 415401,\n",
       " 530367,\n",
       " 598865,\n",
       " 412507,\n",
       " 611460,\n",
       " 96164,\n",
       " 202877,\n",
       " 51621,\n",
       " 168645,\n",
       " 17109,\n",
       " 658964,\n",
       " 450889,\n",
       " 321515,\n",
       " 341737,\n",
       " 159772,\n",
       " 521992,\n",
       " 594628,\n",
       " 151823,\n",
       " 440434,\n",
       " 339226,\n",
       " 239308,\n",
       " 81719,\n",
       " 637234,\n",
       " 339024,\n",
       " 333353,\n",
       " 225043,\n",
       " 424376,\n",
       " 212130,\n",
       " 337139,\n",
       " 625419,\n",
       " 527771,\n",
       " 505135,\n",
       " 103577,\n",
       " 294575,\n",
       " 209515,\n",
       " 287791,\n",
       " 147466,\n",
       " 301625,\n",
       " 595560,\n",
       " 206187,\n",
       " 261574,\n",
       " 183907,\n",
       " 638785,\n",
       " 69024,\n",
       " 567404,\n",
       " 463116,\n",
       " 351689,\n",
       " 606307,\n",
       " 109373,\n",
       " 104477,\n",
       " 330218,\n",
       " 214143,\n",
       " 589187,\n",
       " 581826,\n",
       " 364925,\n",
       " 470689,\n",
       " 635377,\n",
       " 525676,\n",
       " 143743,\n",
       " 472592,\n",
       " 361388,\n",
       " 354080,\n",
       " 413485,\n",
       " 52479,\n",
       " 383581,\n",
       " 229513,\n",
       " 83260,\n",
       " 299474,\n",
       " 117228,\n",
       " 450446,\n",
       " 28781,\n",
       " 634786,\n",
       " 209484,\n",
       " 228055,\n",
       " 681172,\n",
       " 84464,\n",
       " 471195,\n",
       " 238579,\n",
       " 608219,\n",
       " 383362,\n",
       " 440436,\n",
       " 72532,\n",
       " 189798,\n",
       " 475313,\n",
       " 87817,\n",
       " 239732,\n",
       " 67036,\n",
       " 228468,\n",
       " 157629,\n",
       " 272161,\n",
       " 495980,\n",
       " 679435,\n",
       " 279286,\n",
       " 62095,\n",
       " 31848,\n",
       " 526505,\n",
       " 23570,\n",
       " 367367,\n",
       " 41628,\n",
       " 51159,\n",
       " 121454,\n",
       " 9806,\n",
       " 124232,\n",
       " 607193,\n",
       " 287627,\n",
       " 447809,\n",
       " 236576,\n",
       " 166377,\n",
       " 342949,\n",
       " 577170,\n",
       " 342846,\n",
       " 588693,\n",
       " 687439,\n",
       " 40750,\n",
       " 643220,\n",
       " 100924,\n",
       " 386842,\n",
       " 305695,\n",
       " 132116,\n",
       " 676754,\n",
       " 642552,\n",
       " 57376,\n",
       " 280914,\n",
       " 345094,\n",
       " 576019,\n",
       " 127902,\n",
       " 379987,\n",
       " 564710,\n",
       " 374668,\n",
       " 640946,\n",
       " 373298,\n",
       " 132108,\n",
       " 443512,\n",
       " 168075,\n",
       " 563025,\n",
       " 517856,\n",
       " 47582,\n",
       " 90349,\n",
       " 96749,\n",
       " 39670,\n",
       " 316926,\n",
       " 12672,\n",
       " 96543,\n",
       " 340373,\n",
       " 362093,\n",
       " 298279,\n",
       " 527660,\n",
       " 222656,\n",
       " 333888,\n",
       " 240606,\n",
       " 359051,\n",
       " 172146,\n",
       " 237355,\n",
       " 216765,\n",
       " 191486,\n",
       " 521298,\n",
       " 318799,\n",
       " 439892,\n",
       " 612598,\n",
       " 421571,\n",
       " 502893,\n",
       " 450733,\n",
       " 676717,\n",
       " 506754,\n",
       " 162378,\n",
       " 73031,\n",
       " 24512,\n",
       " 59604,\n",
       " 683854,\n",
       " 492878,\n",
       " 174721,\n",
       " 255331,\n",
       " 147291,\n",
       " 642733,\n",
       " 96649,\n",
       " 368742,\n",
       " 369117,\n",
       " 155683,\n",
       " 511087,\n",
       " 418894,\n",
       " 130098,\n",
       " 217727,\n",
       " 207182,\n",
       " 483602,\n",
       " 212065,\n",
       " 639882,\n",
       " 627729,\n",
       " 16913,\n",
       " 113914,\n",
       " 492841,\n",
       " 575279,\n",
       " 431426,\n",
       " 434464,\n",
       " 621883,\n",
       " 119913,\n",
       " 512959,\n",
       " 524840,\n",
       " 260262,\n",
       " 295169,\n",
       " 427565,\n",
       " 162522,\n",
       " 496092,\n",
       " 35391,\n",
       " 332198,\n",
       " 347486,\n",
       " 165104,\n",
       " 664837,\n",
       " 209566,\n",
       " 676964,\n",
       " 504245,\n",
       " 392677,\n",
       " 343556,\n",
       " 402894,\n",
       " 336134,\n",
       " 213038,\n",
       " 383882,\n",
       " 388190,\n",
       " 504958,\n",
       " 622676,\n",
       " 84175,\n",
       " 292382,\n",
       " 410341,\n",
       " 249128,\n",
       " 491730,\n",
       " 50100,\n",
       " 647053,\n",
       " 477211,\n",
       " 306370,\n",
       " 503374,\n",
       " 311811,\n",
       " 59945,\n",
       " 568176,\n",
       " 494757,\n",
       " 313167,\n",
       " 112569,\n",
       " 579552,\n",
       " 195366,\n",
       " 352996,\n",
       " 226767,\n",
       " 142776,\n",
       " 568245,\n",
       " 330041,\n",
       " 244115,\n",
       " 350633,\n",
       " 213960,\n",
       " 464574,\n",
       " 550349,\n",
       " 483794,\n",
       " 67192,\n",
       " 678689,\n",
       " 257570,\n",
       " 395369,\n",
       " 630347,\n",
       " 588565,\n",
       " 633350,\n",
       " 396099,\n",
       " 77251,\n",
       " 657250,\n",
       " 179303,\n",
       " 349114,\n",
       " 330167,\n",
       " 239970,\n",
       " 26175,\n",
       " 451109,\n",
       " 61214,\n",
       " 501704,\n",
       " 401177,\n",
       " 455483,\n",
       " 676074,\n",
       " 483758,\n",
       " 478409,\n",
       " 3026,\n",
       " 298429,\n",
       " 390384,\n",
       " 277870,\n",
       " 441725,\n",
       " 29449,\n",
       " 647120,\n",
       " 235333,\n",
       " 326260,\n",
       " 86032,\n",
       " 512716,\n",
       " 171617,\n",
       " 449513,\n",
       " 349112,\n",
       " 644304,\n",
       " 26131,\n",
       " 103410,\n",
       " 275181,\n",
       " 659463,\n",
       " 271506,\n",
       " 38929,\n",
       " 401036,\n",
       " 63266,\n",
       " 85540,\n",
       " 91893,\n",
       " 556761,\n",
       " 206115,\n",
       " 24835,\n",
       " 615333,\n",
       " 134946,\n",
       " 626714,\n",
       " 5786,\n",
       " 404090,\n",
       " 355642,\n",
       " 114251,\n",
       " 119050,\n",
       " 252714,\n",
       " 503462,\n",
       " 60730,\n",
       " 40092,\n",
       " 594085,\n",
       " 680756,\n",
       " 388617,\n",
       " 247026,\n",
       " 267212,\n",
       " 318437,\n",
       " 169600,\n",
       " 117008,\n",
       " 642872,\n",
       " 289882,\n",
       " 407699,\n",
       " 279261,\n",
       " 165068,\n",
       " 596812,\n",
       " 492611,\n",
       " 620957,\n",
       " 624827,\n",
       " 19533,\n",
       " 600686,\n",
       " 539003,\n",
       " 171924,\n",
       " 510635,\n",
       " 135471,\n",
       " 222556,\n",
       " 76256,\n",
       " 191449,\n",
       " 438526,\n",
       " 668700,\n",
       " 215373,\n",
       " 660548,\n",
       " 557887,\n",
       " 210474,\n",
       " 371039,\n",
       " 420659,\n",
       " 596306,\n",
       " 430555,\n",
       " 491679,\n",
       " 331629,\n",
       " 634114,\n",
       " 673109,\n",
       " 425042,\n",
       " 656624,\n",
       " 202714,\n",
       " 604227,\n",
       " 14117,\n",
       " 109668,\n",
       " 425296,\n",
       " 671962,\n",
       " 2642,\n",
       " 312626,\n",
       " 451725,\n",
       " 154137,\n",
       " 447615,\n",
       " 451035,\n",
       " 396819,\n",
       " 469608,\n",
       " 84790,\n",
       " 390361,\n",
       " 278088,\n",
       " 63152,\n",
       " 176782,\n",
       " 508409,\n",
       " 440254,\n",
       " 640869,\n",
       " 50104,\n",
       " 389477,\n",
       " 251360,\n",
       " 191481,\n",
       " 602656,\n",
       " 42625,\n",
       " 360515,\n",
       " 273788,\n",
       " 245773,\n",
       " 446159,\n",
       " 302840,\n",
       " 60468,\n",
       " 334168,\n",
       " 419468,\n",
       " 420761,\n",
       " 577297,\n",
       " 133102,\n",
       " 260678,\n",
       " 417084,\n",
       " 336993,\n",
       " 155809,\n",
       " 576282,\n",
       " 249353,\n",
       " 146586,\n",
       " 69222,\n",
       " 340839,\n",
       " 18597,\n",
       " 683038,\n",
       " 292168,\n",
       " 338337,\n",
       " 186231,\n",
       " 135650,\n",
       " 602463,\n",
       " 261669,\n",
       " 438886,\n",
       " 238468,\n",
       " 135135,\n",
       " 416973,\n",
       " 280231,\n",
       " 386152,\n",
       " 360167,\n",
       " 477605,\n",
       " 299327,\n",
       " 631614,\n",
       " 385210,\n",
       " 406160,\n",
       " 190186,\n",
       " 21775,\n",
       " 91204,\n",
       " 151442,\n",
       " 277705,\n",
       " 354022,\n",
       " 492323,\n",
       " 605026,\n",
       " 170005,\n",
       " 309539,\n",
       " 308373,\n",
       " 115392,\n",
       " 59182,\n",
       " 368231,\n",
       " 468077,\n",
       " 610326,\n",
       " 381005,\n",
       " 319949,\n",
       " 492725,\n",
       " 185590,\n",
       " 351916,\n",
       " 435626,\n",
       " 252327,\n",
       " 250278,\n",
       " 657688,\n",
       " 367065,\n",
       " 121746,\n",
       " 526219,\n",
       " 439786,\n",
       " 229453,\n",
       " 242263,\n",
       " 507413,\n",
       " 520963,\n",
       " 587768,\n",
       " 18266,\n",
       " 208484,\n",
       " 95157,\n",
       " 547164,\n",
       " 581987,\n",
       " 162291,\n",
       " 83339,\n",
       " 176328,\n",
       " 230931,\n",
       " 30597,\n",
       " 552761,\n",
       " 291582,\n",
       " 618190,\n",
       " 502488,\n",
       " 212497,\n",
       " 419375,\n",
       " 155645,\n",
       " 180878,\n",
       " 473015,\n",
       " 312942,\n",
       " 605131,\n",
       " 91035,\n",
       " 237934,\n",
       " 522954,\n",
       " 625940,\n",
       " 218721,\n",
       " 220857,\n",
       " 159481,\n",
       " 152342,\n",
       " 265921,\n",
       " 548434,\n",
       " 502321,\n",
       " 219483,\n",
       " 85083,\n",
       " 323520,\n",
       " 272060,\n",
       " 89041,\n",
       " 518997,\n",
       " 212732,\n",
       " 45638,\n",
       " 362260,\n",
       " 144183,\n",
       " 223426,\n",
       " 155534,\n",
       " 19832,\n",
       " 32043,\n",
       " 646794,\n",
       " 309119,\n",
       " 293141,\n",
       " 626834,\n",
       " 104495,\n",
       " 615150,\n",
       " 668794,\n",
       " 629760,\n",
       " 154499,\n",
       " 266877,\n",
       " 255828,\n",
       " 196733,\n",
       " 534658,\n",
       " 379660,\n",
       " 200713,\n",
       " 246444,\n",
       " 314999,\n",
       " 416478,\n",
       " 372218,\n",
       " 524533,\n",
       " 558252,\n",
       " 356524,\n",
       " 426919,\n",
       " 29159,\n",
       " 224749,\n",
       " 417926,\n",
       " 63591,\n",
       " 429952,\n",
       " 377945,\n",
       " 72344,\n",
       " 221140,\n",
       " 259086,\n",
       " 553764,\n",
       " 195912,\n",
       " 187031,\n",
       " 203802,\n",
       " 373515,\n",
       " 511191,\n",
       " 292829,\n",
       " 181635,\n",
       " 685911,\n",
       " 574312,\n",
       " 639090,\n",
       " 291338,\n",
       " 637348,\n",
       " 197962,\n",
       " 556100,\n",
       " 596399,\n",
       " 341123,\n",
       " 487777,\n",
       " 96458,\n",
       " 92332,\n",
       " 19651,\n",
       " 404481,\n",
       " 74112,\n",
       " 676743,\n",
       " 131918,\n",
       " 528591,\n",
       " 585372,\n",
       " 118267,\n",
       " 203134,\n",
       " 654642,\n",
       " 363701,\n",
       " 376762,\n",
       " 422516,\n",
       " 410789,\n",
       " 549170,\n",
       " 505373,\n",
       " 639941,\n",
       " 567819,\n",
       " 656525,\n",
       " 191342,\n",
       " 39049,\n",
       " 297638,\n",
       " 649087,\n",
       " 481385,\n",
       " 333816,\n",
       " 330624,\n",
       " 444671,\n",
       " 555271,\n",
       " 336108,\n",
       " 384346,\n",
       " 524492,\n",
       " 462963,\n",
       " 217897,\n",
       " 176558,\n",
       " 672160,\n",
       " 686438,\n",
       " 655984,\n",
       " 513307,\n",
       " 309456,\n",
       " 661891,\n",
       " 629971,\n",
       " 612495,\n",
       " 430188,\n",
       " 473884,\n",
       " 197046,\n",
       " 554277,\n",
       " 271058,\n",
       " 163096,\n",
       " 342507,\n",
       " 524164,\n",
       " 203719,\n",
       " 560045,\n",
       " 503154,\n",
       " 24403,\n",
       " 497915,\n",
       " 460981,\n",
       " 205689,\n",
       " 350767,\n",
       " 669211,\n",
       " 555268,\n",
       " 40096,\n",
       " 49163,\n",
       " 345929,\n",
       " 2665,\n",
       " 665177,\n",
       " 316261,\n",
       " 366025,\n",
       " 326074,\n",
       " 32964,\n",
       " 145619,\n",
       " 139579,\n",
       " 58461,\n",
       " 617347,\n",
       " 293087,\n",
       " 365610,\n",
       " 446718,\n",
       " 413173,\n",
       " 343538,\n",
       " 185676,\n",
       " 58338,\n",
       " 669150,\n",
       " 458050,\n",
       " 388700,\n",
       " 474977,\n",
       " 640929,\n",
       " 665565,\n",
       " 401764,\n",
       " 154902,\n",
       " 135512,\n",
       " 231963,\n",
       " 364293,\n",
       " 127314,\n",
       " 663162,\n",
       " 472683,\n",
       " 255476,\n",
       " 548099,\n",
       " 217328,\n",
       " 311860,\n",
       " 54613,\n",
       " 415418,\n",
       " 403031,\n",
       " 383004,\n",
       " 242681,\n",
       " 90330,\n",
       " 31356,\n",
       " 581348,\n",
       " 230631,\n",
       " 476981,\n",
       " 345012,\n",
       " 573979,\n",
       " 564969,\n",
       " 164663,\n",
       " 102318,\n",
       " 299046,\n",
       " 74200,\n",
       " 203732,\n",
       " 343315,\n",
       " 686701,\n",
       " 171551,\n",
       " 292519,\n",
       " 380997,\n",
       " 355389,\n",
       " 664346,\n",
       " 619441,\n",
       " 538144,\n",
       " 209948,\n",
       " 235458,\n",
       " 625378,\n",
       " 107730,\n",
       " 566554,\n",
       " 273933,\n",
       " 545959,\n",
       " 522093,\n",
       " 378017,\n",
       " 505858,\n",
       " 425781,\n",
       " 472152,\n",
       " 330914,\n",
       " 256524,\n",
       " 279058,\n",
       " 256879,\n",
       " 276154,\n",
       " 636801,\n",
       " 602694,\n",
       " 414333,\n",
       " 164084,\n",
       " 220077,\n",
       " 314848,\n",
       " 280341,\n",
       " 227519,\n",
       " 500083,\n",
       " 131418,\n",
       " 617463,\n",
       " 459048,\n",
       " 10991,\n",
       " 636227,\n",
       " 188403,\n",
       " 308758,\n",
       " 108099,\n",
       " 641906,\n",
       " 418192,\n",
       " 585654,\n",
       " 485719,\n",
       " 457403,\n",
       " 8332,\n",
       " 376323,\n",
       " 374989,\n",
       " 318488,\n",
       " 553583,\n",
       " 610587,\n",
       " 232346,\n",
       " 620294,\n",
       " 328523,\n",
       " 114584,\n",
       " 581390,\n",
       " 660733,\n",
       " 209480,\n",
       " 597091,\n",
       " 396920,\n",
       " 145990,\n",
       " 544356,\n",
       " 206784,\n",
       " 25331,\n",
       " 381201,\n",
       " 217505,\n",
       " 369468,\n",
       " 39364,\n",
       " 658134,\n",
       " 40308,\n",
       " 91216,\n",
       " 566630,\n",
       " 71729,\n",
       " 243365,\n",
       " 566974,\n",
       " 471403,\n",
       " 352971,\n",
       " 209219,\n",
       " 350049,\n",
       " 156543,\n",
       " 21671,\n",
       " 553337,\n",
       " 240596,\n",
       " 681779,\n",
       " 502807,\n",
       " 688034,\n",
       " 143745,\n",
       " 614571,\n",
       " 607080,\n",
       " 515676,\n",
       " 164130,\n",
       " 23540,\n",
       " 105364,\n",
       " 192332,\n",
       " 119730,\n",
       " 657677,\n",
       " 356614,\n",
       " 46625,\n",
       " 359715,\n",
       " 271977,\n",
       " 488883,\n",
       " 179771,\n",
       " 244022,\n",
       " 438756,\n",
       " 516068,\n",
       " 637978,\n",
       " 449382,\n",
       " 308423,\n",
       " 420966,\n",
       " 568814,\n",
       " 157740,\n",
       " 556774,\n",
       " 553063,\n",
       " 423715,\n",
       " 65980,\n",
       " 671127,\n",
       " 624142,\n",
       " 372792,\n",
       " 562706,\n",
       " 452447,\n",
       " 645839,\n",
       " 470316,\n",
       " 502552,\n",
       " 210320,\n",
       " 138870,\n",
       " 117600,\n",
       " 582559,\n",
       " 123497,\n",
       " 353334,\n",
       " 16795,\n",
       " 629446,\n",
       " 436992,\n",
       " 14030,\n",
       " 379215,\n",
       " 153257,\n",
       " 144507,\n",
       " 334195,\n",
       " 99351,\n",
       " 154586,\n",
       " 435388,\n",
       " 439501,\n",
       " 665295,\n",
       " 164662,\n",
       " 325589,\n",
       " 684862,\n",
       " 484823,\n",
       " 394182,\n",
       " 449799,\n",
       " 585569,\n",
       " 241439,\n",
       " 443330,\n",
       " 672889,\n",
       " 539339,\n",
       " 504283,\n",
       " 622603,\n",
       " 26297,\n",
       " 342638,\n",
       " 63438,\n",
       " 303157,\n",
       " 286380,\n",
       " 547193,\n",
       " 374858,\n",
       " 1186,\n",
       " 502198,\n",
       " 235398,\n",
       " 298350,\n",
       " 175832,\n",
       " 440671,\n",
       " 154068,\n",
       " 156775,\n",
       " 48674,\n",
       " 433557,\n",
       " 60522,\n",
       " 544721,\n",
       " 677195,\n",
       " 104549,\n",
       " 523692,\n",
       " 662923,\n",
       " 334556,\n",
       " 659825,\n",
       " 660362,\n",
       " 248804,\n",
       " 301495,\n",
       " 655239,\n",
       " 641263,\n",
       " 183655,\n",
       " 301846,\n",
       " 639306,\n",
       " 531070,\n",
       " 198225,\n",
       " 423941,\n",
       " 101082,\n",
       " 561176,\n",
       " 194236,\n",
       " 82685,\n",
       " 158843,\n",
       " 552715,\n",
       " 667358,\n",
       " 409582,\n",
       " 457573,\n",
       " 433339,\n",
       " 365116,\n",
       " 585456,\n",
       " 163459,\n",
       " 514416,\n",
       " 500370,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(samples)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5300b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688248"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db6e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\Work\\CorrProizv\\samples.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(samples, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ef4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\Work\\CorrProizv\\samples.pickle\", \"rb\") as fp:\n",
    "    samples = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fac981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data to train, validation and test / разделение данных на тренировочный, валидационный и тестовый набор\n",
    "train = samples[:400000]\n",
    "val = samples[400000:500000]\n",
    "test = samples[500000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd0833",
   "metadata": {},
   "source": [
    "##### x data / данные-предикторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5929167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B1.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B11.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B12.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B2.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B3.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B4.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B5.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B6.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B7.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B8.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B8A.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\final_noadj\\\\B9.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\DEM.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\Landcover.tif',\n",
       " 'F:\\\\Work\\\\CorrProizv\\\\Hansen_mosaic.tif']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all data sources / получение всех источников данных\n",
    "path = r'F:\\Work\\CorrProizv\\final_noadj\\\\'\n",
    "files = glob(path+'*.tif')\n",
    "files.append(r'F:\\Work\\CorrProizv\\DEM.tif')\n",
    "files.append(r'F:\\Work\\CorrProizv\\Landcover.tif')\n",
    "files.append(r'F:\\Work\\CorrProizv\\Hansen_mosaic.tif')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a264f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating numpy array / создание массива numpy\n",
    "x_train_conv = np.empty((80896, 139392, 15), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5b2d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Work\\CorrProizv\\final_noadj\\B1.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B11.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B12.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B2.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B3.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B4.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B5.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B6.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B7.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B8.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B8A.tif\n",
      "F:\\Work\\CorrProizv\\final_noadj\\B9.tif\n",
      "F:\\Work\\CorrProizv\\DEM.tif\n",
      "F:\\Work\\CorrProizv\\Landcover.tif\n",
      "F:\\Work\\CorrProizv\\Hansen_mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "#reading all x files / чтение всех данных-предикторов\n",
    "for i in range(len(files)):\n",
    "    with rio.open(files[i]) as bnd:\n",
    "        container = x_train_conv[:,:,i:i+1]\n",
    "        container[:] = np.transpose(np.pad(bnd.read(), ((0,0),(0,89),(0,62)), mode='constant', constant_values=0), axes=[1, 2, 0]).astype('uint16')\n",
    "        print(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a1be3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80896, 139392, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f71d3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\x_train_conv.npy', x_train_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec022bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_conv = np.load(r'F:\\Work\\CorrProizv\\x_train_conv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating x train tiles / генерация тайлов данных-предикторов тренировочного набора\n",
    "x_train = np.empty((len(train), 128, 128, 15), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d856d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    c = tiles[train[i]]\n",
    "    container = x_train[i:i+1,:,:,:]\n",
    "    container[:] = x_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30b64a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 128, 128, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3b8bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\x_train.npy', x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ee9c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating x validation tiles / генерация тайлов данных-предикторов валидационного набора\n",
    "x_val = np.empty((len(val), 128, 128, 15), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62b28ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    c = tiles[val[i]]\n",
    "    container = x_val[i:i+1,:,:,:]\n",
    "    container[:] = x_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab2ecb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 128, 128, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e074b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\x_val.npy', x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8ce0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating x test tiles / генерация тайлов данных-предикторов тестового набора\n",
    "x_test = np.empty((len(test), 128, 128, 15), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a8d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    c = tiles[test[i]]\n",
    "    container = x_test[i:i+1,:,:,:]\n",
    "    container[:] = x_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "879a31d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188248, 128, 128, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24678f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\x_test.npy', x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6931bc",
   "metadata": {},
   "source": [
    "##### y data for tree species model / обучающие данные для модели преобладающих пород"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a89829",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = r'F:\\Work\\CorrProizv\\y_spec2.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31cc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading y file / чтение обучающих данных\n",
    "with rio.open(y) as bnd:\n",
    "    y_train_conv = bnd.read().astype('uint16')\n",
    "    final_trans = bnd.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38976873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80807, 139330)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c22e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_conv = np.pad(y_train_conv, ((0,0),(0,89),(0,62)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481b9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_conv = np.transpose(y_train_conv, axes=[1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32c1bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80896, 139392, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "187b42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y train tiles / генерация тайлов обучающих данных тренировочного набора\n",
    "y_train = np.empty((len(train), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2fb0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    c = tiles[train[i]]\n",
    "    container = y_train[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef017ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 128, 128, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388ab061",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train, num_classes=14, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24821af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 128, 128, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af0c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e7525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y validation tiles / генерация тайлов обучающих данных валидационного набора\n",
    "y_val = np.empty((len(val), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ed9276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    c = tiles[val[i]]\n",
    "    container = y_val[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4b29f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 128, 128, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "690c9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = utils.to_categorical(y_val, num_classes=14, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb0cdf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 128, 128, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2612d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'E:\\Work\\CorrProizv\\y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43ffdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y test tiles / генерация тайлов обучающих данных тестового набора\n",
    "y_test = np.empty((len(test), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48de3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    c = tiles[test[i]]\n",
    "    container = y_test[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcbfc2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188248, 128, 128, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d9e1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(y_test, num_classes=14, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a5d094f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188248, 128, 128, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf26091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7850d6",
   "metadata": {},
   "source": [
    "##### y data for forest types model / обучающие данные для модели типов леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a75e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading y file / чтение обучающих данных\n",
    "y = r'F:\\Work\\CorrProizv\\y_type.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1349d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(y) as bnd:\n",
    "    y_train_conv = bnd.read()\n",
    "    final_trans = bnd.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89fda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_conv = np.pad(y_train_conv, ((0,0),(0,89),(0,62)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25599c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_conv = np.transpose(y_train_conv, axes=[1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92447fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80896, 139392, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a952e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y train tiles / генерация тайлов обучающих данных тренировочного набора\n",
    "y_train = np.empty((len(train), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "083d6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    c = tiles[train[i]]\n",
    "    container = y_train[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23ae88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train, num_classes=10, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "319abafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_types_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49591f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y validation tiles / генерация тайлов обучающих данных валидационного набора\n",
    "y_val = np.empty((len(val), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "397a943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    c = tiles[val[i]]\n",
    "    container = y_val[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc33bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = utils.to_categorical(y_val, num_classes=10, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "914e6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_types_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c93ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y test tiles / генерация тайлов обучающих данных тестового набора\n",
    "y_test = np.empty((len(test), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25818125",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    c = tiles[test[i]]\n",
    "    container = y_test[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0979dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(y_test, num_classes=10, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "019bd419",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_types_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0adb6",
   "metadata": {},
   "source": [
    "##### y data for forest bonitet model / обучающие данные для модели бонитетов леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f63b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading y file / чтение обучающих данных\n",
    "y = r'F:\\Work\\CorrProizv\\y_bon.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f16572",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(y) as bnd:\n",
    "    y_train_conv = bnd.read()\n",
    "    final_trans = bnd.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46418030",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_conv = np.pad(y_train_conv, ((0,0),(0,89),(0,62)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8ff916",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_conv = np.transpose(y_train_conv, axes=[1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c548537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80896, 139392, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27d10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y train tiles / генерация тайлов обучающих данных тренировочного набора\n",
    "y_train = np.empty((len(train), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00706b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    c = tiles[train[i]]\n",
    "    container = y_train[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "718a45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train, num_classes=8, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b343e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_bon_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae7d19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y validation tiles / генерация тайлов обучающих данных валидационного набора\n",
    "y_val = np.empty((len(val), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761eb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    c = tiles[val[i]]\n",
    "    container = y_val[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851d1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = utils.to_categorical(y_val, num_classes=8, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6a4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_bon_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64658a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating y test tiles / генерация тайлов обучающих данных тестового набора\n",
    "y_test = np.empty((len(test), 128, 128, 1), dtype = 'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30ef172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    c = tiles[test[i]]\n",
    "    container = y_test[i:i+1,:,:,:]\n",
    "    container[:] = y_train_conv[c[0]:c[2], c[1]:c[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a844d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(y_test, num_classes=8, dtype = 'float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cda71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\Work\\CorrProizv\\y_bon_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a103b15",
   "metadata": {},
   "source": [
    "### Tree species modelling \n",
    "### Моделирование преобладающих пород\n",
    "##### U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d05befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train and validation data / загрузка тренировочных и валидационных данных\n",
    "x_train = np.load(r'F:\\Work\\CorrProizv\\x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead8a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load(r'F:\\Work\\CorrProizv\\y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4109646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.load(r'F:\\Work\\CorrProizv\\x_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4b8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.load(r'F:\\Work\\CorrProizv\\y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8987653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'keras.optimizers.Adam(learning_rate = 0.01)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variation 1, without batch normalization, performed bad / вариант 1 без пакетной нормализации, показал плохой результат\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "inputs = layers.Input(shape = (128, 128, 15))\n",
    "\n",
    "conv1 = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = layers.Dropout(0.5)(conv4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = layers.Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = layers.Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = layers.Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = layers.Conv2D(512, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = layers.concatenate([drop4,up6], axis = 3)\n",
    "conv6 = layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = layers.Conv2D(256, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = layers.concatenate([conv3,up7], axis = 3)\n",
    "conv7 = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = layers.Conv2D(128, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = layers.concatenate([conv2,up8], axis = 3)\n",
    "conv8 = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = layers.Conv2D(64, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(layers.UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = layers.concatenate([conv1,up9], axis = 3)\n",
    "conv9 = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#conv9 = layers.Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#conv10 = layers.Conv2D(1, 1, activation = 'softmax', padding = 'same')(conv9)\n",
    "conv10 = layers.Conv2D(14, (1, 1), activation = 'softmax', padding = 'same')(conv9)\n",
    "\n",
    "model = models.Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(learning_rate=0.01), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.MeanAbsoluteError(name = 'MAE'),\n",
    "                       tf.keras.metrics.AUC(name='auc')])\n",
    "\"\"\"keras.optimizers.Adam(learning_rate = 0.01)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd702496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added batch normalization, transpose / добавлена пакетная нормализация\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "inputs = layers.Input(shape = (128, 128, 15))\n",
    "\n",
    "conv1 = layers.Conv2D(64, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "norm1 = layers.BatchNormalization()(conv1)\n",
    "relu1 = layers.Activation('relu')(norm1)\n",
    "conv1 = layers.Conv2D(64, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu1)\n",
    "norm1 = layers.BatchNormalization()(conv1)\n",
    "relu1 = layers.Activation('relu')(norm1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(relu1)\n",
    "drop1 = layers.Dropout(0.1)(pool1)\n",
    "conv2 = layers.Conv2D(128, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop1)\n",
    "norm2 = layers.BatchNormalization()(conv2)\n",
    "relu2 = layers.Activation('relu')(norm2)\n",
    "conv2 = layers.Conv2D(128, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu2)\n",
    "norm2 = layers.BatchNormalization()(conv2)\n",
    "relu2 = layers.Activation('relu')(norm2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(relu2)\n",
    "drop2 = layers.Dropout(0.1)(pool2)\n",
    "conv3 = layers.Conv2D(256, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop2)\n",
    "norm3 = layers.BatchNormalization()(conv3)\n",
    "relu3 = layers.Activation('relu')(norm3)\n",
    "conv3 = layers.Conv2D(256, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu3)\n",
    "norm3 = layers.BatchNormalization()(conv3)\n",
    "relu3 = layers.Activation('relu')(norm3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(relu3)\n",
    "drop3 = layers.Dropout(0.1)(pool3)\n",
    "conv4 = layers.Conv2D(512, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop3)\n",
    "norm4 = layers.BatchNormalization()(conv4)\n",
    "relu4 = layers.Activation('relu')(norm4)\n",
    "conv4 = layers.Conv2D(512, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu4)\n",
    "norm4 = layers.BatchNormalization()(conv4)\n",
    "relu4 = layers.Activation('relu')(norm4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(relu4)\n",
    "drop4 = layers.Dropout(0.1)(pool4)\n",
    "\n",
    "conv5 = layers.Conv2D(1024, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop4)\n",
    "norm5 = layers.BatchNormalization()(conv5)\n",
    "relu5 = layers.Activation('relu')(norm5)\n",
    "conv5 = layers.Conv2D(1024, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu5)\n",
    "norm5 = layers.BatchNormalization()(conv5)\n",
    "relu5 = layers.Activation('relu')(norm5)\n",
    "\n",
    "up6 = layers.Conv2DTranspose(512, (2, 2), strides = (2, 2), padding = 'same', kernel_initializer = 'he_normal')(relu5)\n",
    "merge6 = layers.concatenate([relu4,up6], axis = 3)\n",
    "drop6 = layers.Dropout(0.1)(merge6)\n",
    "conv6 = layers.Conv2D(512, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop6)\n",
    "norm6 = layers.BatchNormalization()(conv6)\n",
    "relu6 = layers.Activation('relu')(norm6)\n",
    "conv6 = layers.Conv2D(512, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu6)\n",
    "norm6 = layers.BatchNormalization()(conv6)\n",
    "relu6 = layers.Activation('relu')(norm6)\n",
    "\n",
    "up7 = layers.Conv2DTranspose(256, (2, 2), strides = (2, 2), padding = 'same', kernel_initializer = 'he_normal')(relu6)\n",
    "merge7 = layers.concatenate([relu3,up7], axis = 3)\n",
    "drop7 = layers.Dropout(0.1)(merge7)\n",
    "conv7 = layers.Conv2D(256, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop7)\n",
    "norm7 = layers.BatchNormalization()(conv7)\n",
    "relu7 = layers.Activation('relu')(norm7)\n",
    "conv7 = layers.Conv2D(256, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu7)\n",
    "norm7 = layers.BatchNormalization()(conv7)\n",
    "relu7 = layers.Activation('relu')(norm7)\n",
    "\n",
    "up8 = layers.Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same', kernel_initializer = 'he_normal')(relu7)\n",
    "merge8 = layers.concatenate([relu2,up8], axis = 3)\n",
    "drop8 = layers.Dropout(0.1)(merge8)\n",
    "conv8 = layers.Conv2D(128, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop8)\n",
    "norm8 = layers.BatchNormalization()(conv8)\n",
    "relu8 = layers.Activation('relu')(norm8)\n",
    "conv8 = layers.Conv2D(128, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu8)\n",
    "norm8 = layers.BatchNormalization()(conv8)\n",
    "relu8 = layers.Activation('relu')(norm8)\n",
    "\n",
    "up9 = layers.Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same', kernel_initializer = 'he_normal')(relu8)\n",
    "merge9 = layers.concatenate([relu1,up9], axis = 3)\n",
    "drop9 = layers.Dropout(0.1)(merge9)\n",
    "conv9 = layers.Conv2D(64, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(drop9)\n",
    "norm9 = layers.BatchNormalization()(conv9)\n",
    "relu9 = layers.Activation('relu')(norm9)\n",
    "conv9 = layers.Conv2D(64, (3, 3), padding = 'same', kernel_initializer = 'he_normal')(relu9)\n",
    "norm9 = layers.BatchNormalization()(conv9)\n",
    "relu9 = layers.Activation('relu')(norm9)\n",
    "\n",
    "#conv9 = layers.Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#conv10 = layers.Conv2D(1, 1, activation = 'softmax', padding = 'same')(conv9)\n",
    "conv10 = layers.Conv2D(14, (1, 1), activation = 'softmax', padding = 'same')(relu9)\n",
    "\n",
    "model = models.Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(learning_rate=0.01), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.MeanAbsoluteError(name = 'MAE'),\n",
    "                       tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4c0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 128, 128, 15 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 128, 128, 64) 8704        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 128, 128, 64) 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 64, 64, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 64, 64)   0           max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 64, 64, 128)  73856       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 64, 64, 128)  147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 32, 32, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 128)  0           max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 32, 32, 256)  295168      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 32, 32, 256)  590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 256)  0           max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 16, 16, 512)  1180160     dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 16, 16, 512)  2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 8, 8, 512)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 8, 512)    0           max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 1024)   4719616     dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 1024)   4096        conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 1024)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 1024)   9438208     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 1024)   4096        conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 1024)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 512)  2097664     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 1024) 0           activation_7[0][0]               \n",
      "                                                                 conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 1024) 0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 16, 16, 512)  4719104     dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 16, 16, 512)  2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 512)  0           activation_5[0][0]               \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 512)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 32, 32, 256)  1179904     dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 32, 32, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 256)  1024        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64, 64, 256)  0           activation_3[0][0]               \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 64, 64, 256)  0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 64, 64, 128)  295040      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 64, 64, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 128, 128, 128 0           activation_1[0][0]               \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 128, 128, 128 0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 128, 128, 64) 73792       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 128, 128, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 128, 128, 14) 910         activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,063,054\n",
      "Trainable params: 31,051,278\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "867bb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = r'E:\\Work\\CorrProizv\\unet_species4_1.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee80764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "training_generator = CustomDataGen(X_ds = x_train, y_ds = y_train, batch_size = batch_size)\n",
    "val_generator = CustomDataGen(X_ds = x_val, y_ds = y_val, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b65877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 39833s 2s/step - loss: 0.3403 - accuracy: 0.8746 - precision: 0.9334 - recall: 0.8317 - MAE: 0.0239 - auc: 0.9949 - val_loss: 0.3491 - val_accuracy: 0.8691 - val_precision: 0.9423 - val_recall: 0.8140 - val_MAE: 0.0251 - val_auc: 0.9948\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 40975s 2s/step - loss: 0.3381 - accuracy: 0.8752 - precision: 0.9332 - recall: 0.8330 - MAE: 0.0237 - auc: 0.9949 - val_loss: 0.3302 - val_accuracy: 0.8783 - val_precision: 0.9427 - val_recall: 0.8274 - val_MAE: 0.0242 - val_auc: 0.9954\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 40737s 2s/step - loss: 0.3360 - accuracy: 0.8758 - precision: 0.9331 - recall: 0.8340 - MAE: 0.0236 - auc: 0.9950 - val_loss: 0.3351 - val_accuracy: 0.8769 - val_precision: 0.9309 - val_recall: 0.8390 - val_MAE: 0.0231 - val_auc: 0.9947\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 39910s 2s/step - loss: 0.3316 - accuracy: 0.8772 - precision: 0.9331 - recall: 0.8363 - MAE: 0.0234 - auc: 0.9951 - val_loss: 0.3249 - val_accuracy: 0.8795 - val_precision: 0.9326 - val_recall: 0.8404 - val_MAE: 0.0229 - val_auc: 0.9953\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 42504s 2s/step - loss: 0.3302 - accuracy: 0.8776 - precision: 0.9332 - recall: 0.8369 - MAE: 0.0233 - auc: 0.9952 - val_loss: 0.3232 - val_accuracy: 0.8801 - val_precision: 0.9322 - val_recall: 0.8413 - val_MAE: 0.0230 - val_auc: 0.9955\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 45514s 2s/step - loss: 0.3292 - accuracy: 0.8780 - precision: 0.9331 - recall: 0.8375 - MAE: 0.0233 - auc: 0.9952 - val_loss: 0.3229 - val_accuracy: 0.8803 - val_precision: 0.9402 - val_recall: 0.8331 - val_MAE: 0.0236 - val_auc: 0.9956\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 43763s 2s/step - loss: 0.3281 - accuracy: 0.8783 - precision: 0.9330 - recall: 0.8382 - MAE: 0.0232 - auc: 0.9952 - val_loss: 0.3278 - val_accuracy: 0.8785 - val_precision: 0.9413 - val_recall: 0.8297 - val_MAE: 0.0238 - val_auc: 0.9954\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 43838s 2s/step - loss: 0.3268 - accuracy: 0.8787 - precision: 0.9330 - recall: 0.8390 - MAE: 0.0231 - auc: 0.9953 - val_loss: 0.3209 - val_accuracy: 0.8805 - val_precision: 0.9356 - val_recall: 0.8393 - val_MAE: 0.0230 - val_auc: 0.9955\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 44743s 2s/step - loss: 0.3251 - accuracy: 0.8793 - precision: 0.9329 - recall: 0.8399 - MAE: 0.0230 - auc: 0.9953 - val_loss: 0.3207 - val_accuracy: 0.8811 - val_precision: 0.9361 - val_recall: 0.8398 - val_MAE: 0.0230 - val_auc: 0.9955\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 44202s 2s/step - loss: 0.3232 - accuracy: 0.8798 - precision: 0.9328 - recall: 0.8408 - MAE: 0.0230 - auc: 0.9954 - val_loss: 0.3178 - val_accuracy: 0.8817 - val_precision: 0.9333 - val_recall: 0.8437 - val_MAE: 0.0226 - val_auc: 0.9955\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 44437s 2s/step - loss: 0.3215 - accuracy: 0.8802 - precision: 0.9329 - recall: 0.8413 - MAE: 0.0229 - auc: 0.9954 - val_loss: 0.3159 - val_accuracy: 0.8826 - val_precision: 0.9355 - val_recall: 0.8421 - val_MAE: 0.0227 - val_auc: 0.9956\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 42321s 2s/step - loss: 0.3201 - accuracy: 0.8806 - precision: 0.9330 - recall: 0.8419 - MAE: 0.0228 - auc: 0.9954 - val_loss: 0.3123 - val_accuracy: 0.8834 - val_precision: 0.9349 - val_recall: 0.8444 - val_MAE: 0.0225 - val_auc: 0.9957\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 40993s 2s/step - loss: 0.3188 - accuracy: 0.8809 - precision: 0.9332 - recall: 0.8423 - MAE: 0.0227 - auc: 0.9955 - val_loss: 0.3140 - val_accuracy: 0.8830 - val_precision: 0.9334 - val_recall: 0.8449 - val_MAE: 0.0224 - val_auc: 0.9956\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 41488s 2s/step - loss: 0.3176 - accuracy: 0.8813 - precision: 0.9331 - recall: 0.8429 - MAE: 0.0227 - auc: 0.9955 - val_loss: 0.3180 - val_accuracy: 0.8817 - val_precision: 0.9408 - val_recall: 0.8338 - val_MAE: 0.0236 - val_auc: 0.9957\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 40614s 2s/step - loss: 0.3165 - accuracy: 0.8817 - precision: 0.9331 - recall: 0.8434 - MAE: 0.0226 - auc: 0.9955 - val_loss: 0.3125 - val_accuracy: 0.8835 - val_precision: 0.9395 - val_recall: 0.8389 - val_MAE: 0.0229 - val_auc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "#model training / обучение модели\n",
    "history = model.fit(training_generator, epochs = 15, validation_data = val_generator, callbacks=[model_checkpoint_callback, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a19e1c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.34030860662460327,\n",
       "  0.33812659978866577,\n",
       "  0.3359527587890625,\n",
       "  0.3315733075141907,\n",
       "  0.3302082419395447,\n",
       "  0.32915371656417847,\n",
       "  0.32809051871299744,\n",
       "  0.3268054723739624,\n",
       "  0.3250522315502167,\n",
       "  0.32316771149635315,\n",
       "  0.32151734828948975,\n",
       "  0.3200722336769104,\n",
       "  0.3188088834285736,\n",
       "  0.31764858961105347,\n",
       "  0.3164924383163452],\n",
       " 'accuracy': [0.8745589852333069,\n",
       "  0.8751804828643799,\n",
       "  0.8758410215377808,\n",
       "  0.8772223591804504,\n",
       "  0.8776218891143799,\n",
       "  0.8779910802841187,\n",
       "  0.8783040642738342,\n",
       "  0.8787323236465454,\n",
       "  0.8792669773101807,\n",
       "  0.8797903060913086,\n",
       "  0.8802225589752197,\n",
       "  0.8806324005126953,\n",
       "  0.8809046149253845,\n",
       "  0.8813313841819763,\n",
       "  0.8816524744033813],\n",
       " 'precision': [0.9334188103675842,\n",
       "  0.9331514239311218,\n",
       "  0.9331044554710388,\n",
       "  0.9331106543540955,\n",
       "  0.9331945776939392,\n",
       "  0.9330999851226807,\n",
       "  0.9330139756202698,\n",
       "  0.9330273866653442,\n",
       "  0.932870090007782,\n",
       "  0.9328112006187439,\n",
       "  0.9329028725624084,\n",
       "  0.9329884052276611,\n",
       "  0.9331595301628113,\n",
       "  0.9331328868865967,\n",
       "  0.9331409335136414],\n",
       " 'recall': [0.8317263722419739,\n",
       "  0.8330076932907104,\n",
       "  0.8339887261390686,\n",
       "  0.8362736701965332,\n",
       "  0.8368655443191528,\n",
       "  0.8375145196914673,\n",
       "  0.8382101058959961,\n",
       "  0.8389793038368225,\n",
       "  0.8399330973625183,\n",
       "  0.8407631516456604,\n",
       "  0.841275691986084,\n",
       "  0.8419431447982788,\n",
       "  0.8422630429267883,\n",
       "  0.8428939580917358,\n",
       "  0.8434082865715027],\n",
       " 'MAE': [0.02385566011071205,\n",
       "  0.02374216355383396,\n",
       "  0.023630693554878235,\n",
       "  0.023400666192173958,\n",
       "  0.02332628332078457,\n",
       "  0.023265229538083076,\n",
       "  0.023203851655125618,\n",
       "  0.023132475093007088,\n",
       "  0.02303829789161682,\n",
       "  0.02295215241611004,\n",
       "  0.022876113653182983,\n",
       "  0.02279580384492874,\n",
       "  0.02273954264819622,\n",
       "  0.022674599662423134,\n",
       "  0.022616909816861153],\n",
       " 'auc': [0.9948729276657104,\n",
       "  0.9949328303337097,\n",
       "  0.9949934482574463,\n",
       "  0.9951233267784119,\n",
       "  0.9951567053794861,\n",
       "  0.995186984539032,\n",
       "  0.9952163100242615,\n",
       "  0.9952548742294312,\n",
       "  0.9953002333641052,\n",
       "  0.9953530430793762,\n",
       "  0.995392918586731,\n",
       "  0.9954279065132141,\n",
       "  0.9954656362533569,\n",
       "  0.9954894185066223,\n",
       "  0.9955267310142517],\n",
       " 'val_loss': [0.34910082817077637,\n",
       "  0.33019915223121643,\n",
       "  0.3350713551044464,\n",
       "  0.32486847043037415,\n",
       "  0.3231837749481201,\n",
       "  0.32285457849502563,\n",
       "  0.3278125524520874,\n",
       "  0.320856511592865,\n",
       "  0.3207024335861206,\n",
       "  0.3178325891494751,\n",
       "  0.31592899560928345,\n",
       "  0.31226542592048645,\n",
       "  0.31400206685066223,\n",
       "  0.31802821159362793,\n",
       "  0.3124525845050812],\n",
       " 'val_accuracy': [0.8691218495368958,\n",
       "  0.8783435225486755,\n",
       "  0.8768777847290039,\n",
       "  0.8795140385627747,\n",
       "  0.8800628781318665,\n",
       "  0.8803017735481262,\n",
       "  0.8784505724906921,\n",
       "  0.880506157875061,\n",
       "  0.8811123371124268,\n",
       "  0.8817165493965149,\n",
       "  0.882574200630188,\n",
       "  0.8833900690078735,\n",
       "  0.8829663395881653,\n",
       "  0.8817330598831177,\n",
       "  0.883530855178833],\n",
       " 'val_precision': [0.9422603845596313,\n",
       "  0.9427242875099182,\n",
       "  0.9308805465698242,\n",
       "  0.9325798749923706,\n",
       "  0.9322391152381897,\n",
       "  0.9401775002479553,\n",
       "  0.9412615895271301,\n",
       "  0.9356489181518555,\n",
       "  0.9360655546188354,\n",
       "  0.9332968592643738,\n",
       "  0.9355171322822571,\n",
       "  0.9349309206008911,\n",
       "  0.9333630204200745,\n",
       "  0.9408380389213562,\n",
       "  0.9395284056663513],\n",
       " 'val_recall': [0.8139634132385254,\n",
       "  0.8274451494216919,\n",
       "  0.839008629322052,\n",
       "  0.8403723239898682,\n",
       "  0.8412809371948242,\n",
       "  0.8330547213554382,\n",
       "  0.8297404050827026,\n",
       "  0.8393425941467285,\n",
       "  0.8397592306137085,\n",
       "  0.8437374830245972,\n",
       "  0.8420905470848083,\n",
       "  0.8444287776947021,\n",
       "  0.8449181914329529,\n",
       "  0.8338455557823181,\n",
       "  0.8389376401901245],\n",
       " 'val_MAE': [0.02508043870329857,\n",
       "  0.024151340126991272,\n",
       "  0.02311914786696434,\n",
       "  0.022938264533877373,\n",
       "  0.022968139499425888,\n",
       "  0.023625297471880913,\n",
       "  0.023781118914484978,\n",
       "  0.023012438789010048,\n",
       "  0.023021306842565536,\n",
       "  0.022642383351922035,\n",
       "  0.022733192890882492,\n",
       "  0.022476762533187866,\n",
       "  0.022380834445357323,\n",
       "  0.023596040904521942,\n",
       "  0.022850271314382553],\n",
       " 'val_auc': [0.9947657585144043,\n",
       "  0.9954004287719727,\n",
       "  0.9947232604026794,\n",
       "  0.9953233599662781,\n",
       "  0.9954641461372375,\n",
       "  0.9955589771270752,\n",
       "  0.9953684210777283,\n",
       "  0.9955205917358398,\n",
       "  0.9954749345779419,\n",
       "  0.9955483078956604,\n",
       "  0.9956029653549194,\n",
       "  0.9956976175308228,\n",
       "  0.9955564141273499,\n",
       "  0.9957339763641357,\n",
       "  0.995797336101532],\n",
       " 'lr': [0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e968563",
   "metadata": {},
   "source": [
    "##### DEEPLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45f620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaba56e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 128, 128, 15 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 15) 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 64, 64, 64)   47104       conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 256)    0           conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 1, 1, 256)    65792       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 1, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 256)    65536       conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_36 (TFOpLambda)      (None, 1, 1, 256)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 256)    1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 256)    1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 8, 8, 256)    0           tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_37 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_38 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_39 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_40 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 1280)   0           up_sampling2d_12[0][0]           \n",
      "                                                                 tf.nn.relu_37[0][0]              \n",
      "                                                                 tf.nn.relu_38[0][0]              \n",
      "                                                                 tf.nn.relu_39[0][0]              \n",
      "                                                                 tf.nn.relu_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    327680      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 256)    1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 48)   3072        conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_41 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 48)   192         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 32, 32, 256)  0           tf.nn.relu_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_42 (TFOpLambda)      (None, 32, 32, 48)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 304)  0           up_sampling2d_13[0][0]           \n",
      "                                                                 tf.nn.relu_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 256)  700416      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 256)  1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_43 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 256)  589824      tf.nn.relu_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 256)  1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_44 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 128, 128, 256 0           tf.nn.relu_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 14) 3598        up_sampling2d_14[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 11,893,326\n",
      "Trainable params: 11,860,590\n",
      "Non-trainable params: 32,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = tf.keras.Input(shape=(image_size, image_size, 15))\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=None, include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), activation = 'softmax',  padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "model = DeeplabV3Plus(image_size=128, num_classes=14)\n",
    "model.compile(optimizer = optimizers.Adam(learning_rate=0.01), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.MeanAbsoluteError(name = 'MAE'),\n",
    "                       tf.keras.metrics.AUC(name='auc')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f48a8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = r'E:\\Work\\CorrProizv\\deeplab_species1_1.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8948e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "training_generator = CustomDataGen(X_ds = x_train, y_ds = y_train, batch_size = batch_size)\n",
    "val_generator = CustomDataGen(X_ds = x_val, y_ds = y_val, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 26444s 1s/step - loss: 0.2995 - accuracy: 0.8873 - precision: 0.9324 - recall: 0.8531 - MAE: 0.0217 - auc: 0.9960 - val_loss: 0.3074 - val_accuracy: 0.8848 - val_precision: 0.9315 - val_recall: 0.8504 - val_MAE: 0.0219 - val_auc: 0.9957\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 25508s 1s/step - loss: 0.2983 - accuracy: 0.8878 - precision: 0.9324 - recall: 0.8538 - MAE: 0.0216 - auc: 0.9960 - val_loss: 0.3148 - val_accuracy: 0.8813 - val_precision: 0.9345 - val_recall: 0.8419 - val_MAE: 0.0226 - val_auc: 0.9956\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 26451s 1s/step - loss: 0.2972 - accuracy: 0.8882 - precision: 0.9324 - recall: 0.8545 - MAE: 0.0215 - auc: 0.9960 - val_loss: 0.3133 - val_accuracy: 0.8826 - val_precision: 0.9302 - val_recall: 0.8476 - val_MAE: 0.0226 - val_auc: 0.9956\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 26035s 1s/step - loss: 0.2960 - accuracy: 0.8887 - precision: 0.9324 - recall: 0.8553 - MAE: 0.0215 - auc: 0.9961 - val_loss: 0.3100 - val_accuracy: 0.8837 - val_precision: 0.9345 - val_recall: 0.8458 - val_MAE: 0.0224 - val_auc: 0.9958\n",
      "Epoch 5/15\n",
      " 2584/25000 [==>...........................] - ETA: 6:03:32 - loss: 0.2898 - accuracy: 0.8915 - precision: 0.9332 - recall: 0.8593 - MAE: 0.0210 - auc: 0.9962"
     ]
    }
   ],
   "source": [
    "#model showed better performance than U-Net / модель показала лучшие результаты, чем U-Net\n",
    "#only last 5 epochs are showed / показаны только результаты последних 5 эпох\n",
    "history = model.fit(training_generator, epochs = 15, validation_data = val_generator, callbacks=[model_checkpoint_callback, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "783995b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ad6a88820>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8f741",
   "metadata": {},
   "source": [
    "### Testing tree species model\n",
    "### Тестирование модели преобладающих пород"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275d7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test data / загрузка тестовых данных\n",
    "x_test = np.load(r'F:\\Work\\CorrProizv\\x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7baaf72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load(r'F:\\Work\\CorrProizv\\y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2e4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model / загрузка модели\n",
    "model = tf.keras.models.load_model(r'E:\\Work\\CorrProizv\\deeplab_species1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9d597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "test_generator = CustomDataGen(X_ds = x_test, y_ds = y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03206b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11765/11765 [==============================] - 3204s 272ms/step - loss: 0.3119 - accuracy: 0.8830 - precision: 0.9354 - recall: 0.8435 - MAE: 0.0228 - auc: 0.9957\n"
     ]
    }
   ],
   "source": [
    "#testing / тестирование\n",
    "results = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285bc27",
   "metadata": {},
   "source": [
    "### Tree species map\n",
    "### Карта преобладающих пород"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d2b032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model / загрузка модели\n",
    "model = tf.keras.models.load_model(r'E:\\Work\\CorrProizv\\deeplab_species1_1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9587e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating tiles / генерация тайлов\n",
    "tiles = []\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "x2 = 128\n",
    "y2 = 128\n",
    "for i in range (0,632,1):\n",
    "    for i in range(0,1089,1):\n",
    "        tiles.append((x1,y1,x2,y2))\n",
    "        y1 +=128\n",
    "        y2 +=128\n",
    "    y1=0\n",
    "    y2=128\n",
    "    x1+=128\n",
    "    x2+=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049c884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train, validation and test split / загрузка тренировочного, валидационного и тестового наборов\n",
    "with open(r\"E:\\Work\\CorrProizv\\samples.pickle\", \"rb\") as fp:\n",
    "    samples = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49fad27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = samples[:400000]\n",
    "val = samples[400000:500000]\n",
    "test = samples[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddaf01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading y data raster as a reference / загрузка файла с обучающими данными для привязки итогового растра\n",
    "y = r'F:\\Work\\CorrProizv\\y_spec2.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aecfa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yband = rio.open(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95310d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80807, 139330)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yband.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "620ebd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('int16',)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yband.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f753ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating prediction array / создание массива для моделирования\n",
    "y_pred = np.zeros((80896, 139392), dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f27297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for train data / моделирование преобладающей породы для тренировочных даннных\n",
    "x_train = np.load(r'F:\\Work\\CorrProizv\\x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2dba8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    prediction = model.predict(x_train[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = train[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b298a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62876ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for validation data / моделирование преобладающей породы для валидационных даннных\n",
    "x_val = np.load(r'F:\\Work\\CorrProizv\\x_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff19e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    prediction = model.predict(x_val[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = val[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eea4fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for test data / моделирование преобладающей породы для тестовых даннных\n",
    "x_test = np.load(r'F:\\Work\\CorrProizv\\x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd6134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    prediction = model.predict(x_test[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = test[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e41b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80896, 139392)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a6537bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred[:80807, :139330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f508e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving map into raster file / сохранение карты в растровый файл\n",
    "with rio.open(\n",
    "    r'F:\\Work\\CorrProizv\\y_pred_deeplab.tif',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=y_pred.shape[0],\n",
    "    width=y_pred.shape[1],\n",
    "    count=1,\n",
    "    dtype=y_pred.dtype,\n",
    "    compress = 'deflate',\n",
    "    PREDICTOR = 1,\n",
    "    ZLEVEL=9,\n",
    "    crs=yband.crs,\n",
    "    transform=yband.transform,\n",
    "    nodata = 0\n",
    ") as outfile:\n",
    "    outfile.write(y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eab450",
   "metadata": {},
   "source": [
    "### Forest types modelling \n",
    "### Моделирование типов леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73f8fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train and validation data / загрузка тренировочных и валидационных данных\n",
    "x_train = np.load(r'F:\\Work\\CorrProizv\\x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ffbe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load(r'F:\\Work\\CorrProizv\\y_types_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18f71d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.load(r'F:\\Work\\CorrProizv\\x_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b68f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.load(r'F:\\Work\\CorrProizv\\y_types_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abb88b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51ab2e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 15 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 15) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 64, 64, 64)   47104       conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 256)    65792       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 1, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    65536       conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, 1, 1, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 256)    0           tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_10 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_11 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_12 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_13 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 1280)   0           up_sampling2d_3[0][0]            \n",
      "                                                                 tf.nn.relu_10[0][0]              \n",
      "                                                                 tf.nn.relu_11[0][0]              \n",
      "                                                                 tf.nn.relu_12[0][0]              \n",
      "                                                                 tf.nn.relu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    327680      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   3072        conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_14 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0           tf.nn.relu_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_15 (TFOpLambda)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 304)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 256)  700416      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_16 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 256)  589824      tf.nn.relu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_17 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           tf.nn.relu_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 10) 2570        up_sampling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 11,892,298\n",
      "Trainable params: 11,859,562\n",
      "Non-trainable params: 32,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = tf.keras.Input(shape=(image_size, image_size, 15))\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=None, include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), activation = 'softmax',  padding=\"same\")(x)\n",
    "    return tf.keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "model = DeeplabV3Plus(image_size=128, num_classes=10)\n",
    "model.compile(optimizer = optimizers.Adam(learning_rate=0.01), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.MeanAbsoluteError(name = 'MAE'),\n",
    "                       tf.keras.metrics.AUC(name='auc')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dce0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = r'E:\\Work\\CorrProizv\\deeplab_types.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6665168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "training_generator = CustomDataGen(X_ds = x_train, y_ds = y_train, batch_size = batch_size)\n",
    "val_generator = CustomDataGen(X_ds = x_val, y_ds = y_val, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d27e1e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 28255s 1s/step - loss: 0.3951 - accuracy: 0.8478 - precision: 0.9781 - recall: 0.7859 - MAE: 0.0360 - auc: 0.9902 - val_loss: 0.3741 - val_accuracy: 0.8546 - val_precision: 0.9842 - val_recall: 0.7889 - val_MAE: 0.0350 - val_auc: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\geo\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 21470s 859ms/step - loss: 0.3672 - accuracy: 0.8584 - precision: 0.9737 - recall: 0.7968 - MAE: 0.0341 - auc: 0.9917 - val_loss: 0.3630 - val_accuracy: 0.8600 - val_precision: 0.9655 - val_recall: 0.8060 - val_MAE: 0.0327 - val_auc: 0.9915\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 27364s 1s/step - loss: 0.3578 - accuracy: 0.8622 - precision: 0.9710 - recall: 0.8017 - MAE: 0.0335 - auc: 0.9922 - val_loss: 0.5043 - val_accuracy: 0.8229 - val_precision: 0.9107 - val_recall: 0.7891 - val_MAE: 0.0381 - val_auc: 0.9861\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 30472s 1s/step - loss: 0.3424 - accuracy: 0.8681 - precision: 0.9689 - recall: 0.8087 - MAE: 0.0325 - auc: 0.9929 - val_loss: 0.3484 - val_accuracy: 0.8659 - val_precision: 0.9518 - val_recall: 0.8190 - val_MAE: 0.0317 - val_auc: 0.9926\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 23521s 941ms/step - loss: 0.3385 - accuracy: 0.8696 - precision: 0.9676 - recall: 0.8111 - MAE: 0.0322 - auc: 0.9931 - val_loss: 0.3395 - val_accuracy: 0.8700 - val_precision: 0.9606 - val_recall: 0.8150 - val_MAE: 0.0321 - val_auc: 0.9930\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 23440s 938ms/step - loss: 0.3357 - accuracy: 0.8709 - precision: 0.9668 - recall: 0.8127 - MAE: 0.0320 - auc: 0.9932 - val_loss: 0.3335 - val_accuracy: 0.8720 - val_precision: 0.9619 - val_recall: 0.8177 - val_MAE: 0.0316 - val_auc: 0.9933\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 30676s 1s/step - loss: 0.3333 - accuracy: 0.8718 - precision: 0.9660 - recall: 0.8140 - MAE: 0.0318 - auc: 0.9933 - val_loss: 0.3338 - val_accuracy: 0.8720 - val_precision: 0.9568 - val_recall: 0.8210 - val_MAE: 0.0312 - val_auc: 0.9933\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 25504s 1s/step - loss: 0.3288 - accuracy: 0.8736 - precision: 0.9649 - recall: 0.8167 - MAE: 0.0315 - auc: 0.9935 - val_loss: 0.3239 - val_accuracy: 0.8762 - val_precision: 0.9634 - val_recall: 0.8195 - val_MAE: 0.0311 - val_auc: 0.9937\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 21598s 864ms/step - loss: 0.3272 - accuracy: 0.8742 - precision: 0.9643 - recall: 0.8177 - MAE: 0.0314 - auc: 0.9935 - val_loss: 0.3234 - val_accuracy: 0.8766 - val_precision: 0.9656 - val_recall: 0.8194 - val_MAE: 0.0310 - val_auc: 0.9937\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 22167s 887ms/step - loss: 0.3258 - accuracy: 0.8748 - precision: 0.9638 - recall: 0.8185 - MAE: 0.0313 - auc: 0.9936 - val_loss: 0.3235 - val_accuracy: 0.8759 - val_precision: 0.9629 - val_recall: 0.8214 - val_MAE: 0.0309 - val_auc: 0.9936\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_generator, epochs = 10, validation_data = val_generator, callbacks=[model_checkpoint_callback, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e80ac03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.39514750242233276,\n",
       "  0.367192804813385,\n",
       "  0.35779261589050293,\n",
       "  0.34243571758270264,\n",
       "  0.3385457694530487,\n",
       "  0.3356682062149048,\n",
       "  0.33329635858535767,\n",
       "  0.32882159948349,\n",
       "  0.3271735608577728,\n",
       "  0.3258102834224701],\n",
       " 'accuracy': [0.8478060960769653,\n",
       "  0.8584378361701965,\n",
       "  0.8622170090675354,\n",
       "  0.8680524826049805,\n",
       "  0.8695633411407471,\n",
       "  0.8708953261375427,\n",
       "  0.871849775314331,\n",
       "  0.8735653758049011,\n",
       "  0.8742461800575256,\n",
       "  0.8747755289077759],\n",
       " 'precision': [0.9781430959701538,\n",
       "  0.973706841468811,\n",
       "  0.9709579348564148,\n",
       "  0.9688681960105896,\n",
       "  0.9676061868667603,\n",
       "  0.9667657017707825,\n",
       "  0.9659939408302307,\n",
       "  0.9648558497428894,\n",
       "  0.9642929434776306,\n",
       "  0.9637888669967651],\n",
       " 'recall': [0.7859051823616028,\n",
       "  0.7968304753303528,\n",
       "  0.8016785979270935,\n",
       "  0.8087245225906372,\n",
       "  0.8110524415969849,\n",
       "  0.8127419948577881,\n",
       "  0.8139996528625488,\n",
       "  0.8166502118110657,\n",
       "  0.8176752328872681,\n",
       "  0.8184917569160461],\n",
       " 'MAE': [0.0360274575650692,\n",
       "  0.034141622483730316,\n",
       "  0.033463530242443085,\n",
       "  0.03247259929776192,\n",
       "  0.032183486968278885,\n",
       "  0.031964924186468124,\n",
       "  0.03179001063108444,\n",
       "  0.031478673219680786,\n",
       "  0.03135522082448006,\n",
       "  0.03125790134072304],\n",
       " 'auc': [0.990247368812561,\n",
       "  0.9917287230491638,\n",
       "  0.9921736121177673,\n",
       "  0.9928896427154541,\n",
       "  0.9930670261383057,\n",
       "  0.9931825995445251,\n",
       "  0.9932880401611328,\n",
       "  0.9934800267219543,\n",
       "  0.9935470819473267,\n",
       "  0.9936041235923767],\n",
       " 'val_loss': [0.37408557534217834,\n",
       "  0.36298829317092896,\n",
       "  0.5042501091957092,\n",
       "  0.34843528270721436,\n",
       "  0.3395404815673828,\n",
       "  0.333501398563385,\n",
       "  0.3338043689727783,\n",
       "  0.32388919591903687,\n",
       "  0.3233618140220642,\n",
       "  0.32353028655052185],\n",
       " 'val_accuracy': [0.8546499013900757,\n",
       "  0.8599732518196106,\n",
       "  0.8228882551193237,\n",
       "  0.8659436106681824,\n",
       "  0.8699859976768494,\n",
       "  0.8719748258590698,\n",
       "  0.871995210647583,\n",
       "  0.876193642616272,\n",
       "  0.8765510320663452,\n",
       "  0.8758618235588074],\n",
       " 'val_precision': [0.9842461943626404,\n",
       "  0.965546190738678,\n",
       "  0.9107494354248047,\n",
       "  0.9518361687660217,\n",
       "  0.9606214165687561,\n",
       "  0.9618756771087646,\n",
       "  0.9567803144454956,\n",
       "  0.9633878469467163,\n",
       "  0.9656182527542114,\n",
       "  0.9629181623458862],\n",
       " 'val_recall': [0.78891521692276,\n",
       "  0.8059588074684143,\n",
       "  0.7891473770141602,\n",
       "  0.8190001249313354,\n",
       "  0.8150451183319092,\n",
       "  0.8176653981208801,\n",
       "  0.8210405111312866,\n",
       "  0.8194687366485596,\n",
       "  0.8194345831871033,\n",
       "  0.8213630318641663],\n",
       " 'val_MAE': [0.035015400499105453,\n",
       "  0.03268168866634369,\n",
       "  0.038058750331401825,\n",
       "  0.031658563762903214,\n",
       "  0.03207344561815262,\n",
       "  0.03162514790892601,\n",
       "  0.03116871416568756,\n",
       "  0.031069958582520485,\n",
       "  0.031001657247543335,\n",
       "  0.030939608812332153],\n",
       " 'val_auc': [0.9914175868034363,\n",
       "  0.9915305972099304,\n",
       "  0.9860984683036804,\n",
       "  0.9926128387451172,\n",
       "  0.9930198192596436,\n",
       "  0.9933246970176697,\n",
       "  0.9932655096054077,\n",
       "  0.993707537651062,\n",
       "  0.9936699271202087,\n",
       "  0.9936442375183105],\n",
       " 'lr': [0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1a5cb",
   "metadata": {},
   "source": [
    "### Testing forest types model\n",
    "### Тестирование модели типов леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10e236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test data / загрузка тестовых данных\n",
    "x_test = np.load(r'F:\\Work\\CorrProizv\\x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8831a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load(r'F:\\Work\\CorrProizv\\y_types_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d89293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model / загрузка модели\n",
    "model = tf.keras.models.load_model(r'E:\\Work\\CorrProizv\\deeplab_types.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "test_generator = CustomDataGen(X_ds = x_test, y_ds = y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6827691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11765/11765 [==============================] - 3286s 279ms/step - loss: 0.3264 - accuracy: 0.8751 - precision: 0.9651 - recall: 0.8182 - MAE: 0.0312 - auc: 0.9936\n"
     ]
    }
   ],
   "source": [
    "#testing / тестирование\n",
    "results = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8bd5df",
   "metadata": {},
   "source": [
    "### Forest types map\n",
    "### Карта типов леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347ae819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model / загрузка модели\n",
    "model = tf.keras.models.load_model(r'E:\\Work\\CorrProizv\\deeplab_types.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71edd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating tiles / генерация тайлов\n",
    "tiles = []\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "x2 = 128\n",
    "y2 = 128\n",
    "for i in range (0,632,1):\n",
    "    for i in range(0,1089,1):\n",
    "        tiles.append((x1,y1,x2,y2))\n",
    "        y1 +=128\n",
    "        y2 +=128\n",
    "    y1=0\n",
    "    y2=128\n",
    "    x1+=128\n",
    "    x2+=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfa7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train, validation and test split / загрузка тренировочного, валидационного и тестового наборов\n",
    "with open(r\"E:\\Work\\CorrProizv\\samples.pickle\", \"rb\") as fp:\n",
    "    samples = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe319b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = samples[:400000]\n",
    "val = samples[400000:500000]\n",
    "test = samples[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c33ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading y data raster as a reference / загрузка файла с обучающими данными для привязки итогового растра\n",
    "y = r'F:\\Work\\CorrProizv\\y_spec2.tif'\n",
    "yband = rio.open(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c680b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating prediction array / создание массива для моделирования\n",
    "y_pred = np.zeros((80896, 139392), dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6204b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for train data / моделирование преобладающей породы для тренировочных даннных\n",
    "x_train = np.load(r'F:\\Work\\CorrProizv\\x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce96dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    prediction = model.predict(x_train[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = train[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de3de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for validation data / моделирование преобладающей породы для валидационных даннных\n",
    "x_val = np.load(r'F:\\Work\\CorrProizv\\x_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e992ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    prediction = model.predict(x_val[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = val[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73815bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for test data / моделирование преобладающей породы для тестовых даннных\n",
    "x_test = np.load(r'F:\\Work\\CorrProizv\\x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad7afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    prediction = model.predict(x_test[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = test[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca0a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred[:80807, :139330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ecc8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving map into raster file / сохранение карты в растровый файл\n",
    "with rio.open(\n",
    "    r'F:\\Work\\CorrProizv\\y_pred_types.tif',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=y_pred.shape[0],\n",
    "    width=y_pred.shape[1],\n",
    "    count=1,\n",
    "    dtype=y_pred.dtype,\n",
    "    compress = 'deflate',\n",
    "    PREDICTOR = 1,\n",
    "    ZLEVEL=9,\n",
    "    crs=yband.crs,\n",
    "    transform=yband.transform,\n",
    "    nodata = 0\n",
    ") as outfile:\n",
    "    outfile.write(y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c678f87",
   "metadata": {},
   "source": [
    "### Forest bonitet modelling \n",
    "### Моделирование бонитета леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2dcf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train and validation data / загрузка тренировочных и валидационных данных\n",
    "x_train = np.load(r'F:\\Work\\CorrProizv\\x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load(r'F:\\Work\\CorrProizv\\y_bon_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "755b908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.load(r'F:\\Work\\CorrProizv\\x_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93251d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.load(r'F:\\Work\\CorrProizv\\y_bon_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f64d0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31470c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 15 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 15) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 64, 64, 64)   47104       conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 256)    65792       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 1, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    65536       conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    589824      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, 1, 1, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 256)    0           tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_10 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_11 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_12 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_13 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 1280)   0           up_sampling2d_3[0][0]            \n",
      "                                                                 tf.nn.relu_10[0][0]              \n",
      "                                                                 tf.nn.relu_11[0][0]              \n",
      "                                                                 tf.nn.relu_12[0][0]              \n",
      "                                                                 tf.nn.relu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    327680      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   3072        conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_14 (TFOpLambda)      (None, 8, 8, 256)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0           tf.nn.relu_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_15 (TFOpLambda)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 304)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 256)  700416      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_16 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 256)  589824      tf.nn.relu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_17 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           tf.nn.relu_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 8)  2056        up_sampling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 11,891,784\n",
      "Trainable params: 11,859,048\n",
      "Non-trainable params: 32,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = tf.keras.Input(shape=(image_size, image_size, 15))\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=None, include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), activation = 'softmax',  padding=\"same\")(x)\n",
    "    return tf.keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "model = DeeplabV3Plus(image_size=128, num_classes=8)\n",
    "model.compile(optimizer = optimizers.Adam(learning_rate=0.01), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.MeanAbsoluteError(name = 'MAE'),\n",
    "                       tf.keras.metrics.AUC(name='auc')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "720264c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = r'E:\\Work\\CorrProizv\\deeplab_bon.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bb44324",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "training_generator = CustomDataGen(X_ds = x_train, y_ds = y_train, batch_size = batch_size)\n",
    "val_generator = CustomDataGen(X_ds = x_val, y_ds = y_val, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb100dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 17713s 708ms/step - loss: 0.3195 - accuracy: 0.8648 - precision: 0.9548 - recall: 0.7973 - MAE: 0.0414 - auc: 0.9921 - val_loss: 0.3501 - val_accuracy: 0.8606 - val_precision: 0.8866 - val_recall: 0.8478 - val_MAE: 0.0385 - val_auc: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\geo\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 17984s 719ms/step - loss: 0.2943 - accuracy: 0.8736 - precision: 0.9488 - recall: 0.8130 - MAE: 0.0392 - auc: 0.9932 - val_loss: 0.3581 - val_accuracy: 0.8517 - val_precision: 0.9516 - val_recall: 0.7942 - val_MAE: 0.0419 - val_auc: 0.9897\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 17051s 682ms/step - loss: 0.2794 - accuracy: 0.8797 - precision: 0.9450 - recall: 0.8238 - MAE: 0.0378 - auc: 0.9939 - val_loss: 0.2738 - val_accuracy: 0.8811 - val_precision: 0.9286 - val_recall: 0.8430 - val_MAE: 0.0364 - val_auc: 0.9941\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 16652s 666ms/step - loss: 0.2758 - accuracy: 0.8811 - precision: 0.9428 - recall: 0.8280 - MAE: 0.0374 - auc: 0.9940 - val_loss: 0.2716 - val_accuracy: 0.8820 - val_precision: 0.9364 - val_recall: 0.8349 - val_MAE: 0.0372 - val_auc: 0.9942\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 16909s 676ms/step - loss: 0.2733 - accuracy: 0.8821 - precision: 0.9412 - recall: 0.8309 - MAE: 0.0372 - auc: 0.9941 - val_loss: 0.2694 - val_accuracy: 0.8838 - val_precision: 0.9322 - val_recall: 0.8442 - val_MAE: 0.0361 - val_auc: 0.9943\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 16956s 678ms/step - loss: 0.2711 - accuracy: 0.8831 - precision: 0.9397 - recall: 0.8337 - MAE: 0.0369 - auc: 0.9942 - val_loss: 0.2809 - val_accuracy: 0.8778 - val_precision: 0.9338 - val_recall: 0.8325 - val_MAE: 0.0377 - val_auc: 0.9938\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 17160s 686ms/step - loss: 0.2673 - accuracy: 0.8847 - precision: 0.9376 - recall: 0.8384 - MAE: 0.0365 - auc: 0.9944 - val_loss: 0.2635 - val_accuracy: 0.8859 - val_precision: 0.9362 - val_recall: 0.8417 - val_MAE: 0.0361 - val_auc: 0.9946\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 16766s 671ms/step - loss: 0.2659 - accuracy: 0.8852 - precision: 0.9370 - recall: 0.8399 - MAE: 0.0364 - auc: 0.9944 - val_loss: 0.2671 - val_accuracy: 0.8853 - val_precision: 0.9293 - val_recall: 0.8478 - val_MAE: 0.0360 - val_auc: 0.9943\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 16641s 666ms/step - loss: 0.2648 - accuracy: 0.8856 - precision: 0.9364 - recall: 0.8411 - MAE: 0.0363 - auc: 0.9945 - val_loss: 0.2640 - val_accuracy: 0.8860 - val_precision: 0.9351 - val_recall: 0.8436 - val_MAE: 0.0360 - val_auc: 0.9945\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 16958s 678ms/step - loss: 0.2637 - accuracy: 0.8862 - precision: 0.9357 - recall: 0.8428 - MAE: 0.0362 - auc: 0.9945 - val_loss: 0.2794 - val_accuracy: 0.8774 - val_precision: 0.9299 - val_recall: 0.8378 - val_MAE: 0.0370 - val_auc: 0.9939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_generator, epochs = 10, validation_data = val_generator, callbacks=[model_checkpoint_callback, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deb0bf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3194510340690613,\n",
       "  0.2943100333213806,\n",
       "  0.2793913185596466,\n",
       "  0.27578482031822205,\n",
       "  0.2732796370983124,\n",
       "  0.2711236774921417,\n",
       "  0.2672930955886841,\n",
       "  0.2658865749835968,\n",
       "  0.2648017704486847,\n",
       "  0.26372748613357544],\n",
       " 'accuracy': [0.8647693991661072,\n",
       "  0.8735628724098206,\n",
       "  0.8796509504318237,\n",
       "  0.8811419606208801,\n",
       "  0.8821361064910889,\n",
       "  0.8830742835998535,\n",
       "  0.8846959471702576,\n",
       "  0.8852378726005554,\n",
       "  0.8856346607208252,\n",
       "  0.8862057328224182],\n",
       " 'precision': [0.9548406004905701,\n",
       "  0.9487602710723877,\n",
       "  0.9449564218521118,\n",
       "  0.9427663683891296,\n",
       "  0.9412365555763245,\n",
       "  0.9397451281547546,\n",
       "  0.9375885128974915,\n",
       "  0.9370201230049133,\n",
       "  0.9364311099052429,\n",
       "  0.9357175230979919],\n",
       " 'recall': [0.7973067760467529,\n",
       "  0.8130154013633728,\n",
       "  0.8238339424133301,\n",
       "  0.8280373215675354,\n",
       "  0.8309144377708435,\n",
       "  0.8336891531944275,\n",
       "  0.838403582572937,\n",
       "  0.8398922085762024,\n",
       "  0.8411339521408081,\n",
       "  0.8427765369415283],\n",
       " 'MAE': [0.04141265153884888,\n",
       "  0.039200033992528915,\n",
       "  0.03781045973300934,\n",
       "  0.03742637485265732,\n",
       "  0.03717384859919548,\n",
       "  0.036942657083272934,\n",
       "  0.03654972091317177,\n",
       "  0.03640022128820419,\n",
       "  0.036282289773225784,\n",
       "  0.0361519493162632],\n",
       " 'auc': [0.9920848608016968,\n",
       "  0.9932420253753662,\n",
       "  0.9938791394233704,\n",
       "  0.9940338134765625,\n",
       "  0.9941412806510925,\n",
       "  0.9942294955253601,\n",
       "  0.9943814873695374,\n",
       "  0.9944374561309814,\n",
       "  0.9944813251495361,\n",
       "  0.9945257306098938],\n",
       " 'val_loss': [0.35009855031967163,\n",
       "  0.35810819268226624,\n",
       "  0.2737613916397095,\n",
       "  0.27155303955078125,\n",
       "  0.26939988136291504,\n",
       "  0.28093239665031433,\n",
       "  0.26351362466812134,\n",
       "  0.26708221435546875,\n",
       "  0.26403501629829407,\n",
       "  0.2793974280357361],\n",
       " 'val_accuracy': [0.8605533838272095,\n",
       "  0.8517423272132874,\n",
       "  0.8810678124427795,\n",
       "  0.8820064663887024,\n",
       "  0.8837505578994751,\n",
       "  0.8778058886528015,\n",
       "  0.8859460353851318,\n",
       "  0.8852897882461548,\n",
       "  0.8859677910804749,\n",
       "  0.8774075508117676],\n",
       " 'val_precision': [0.8866164684295654,\n",
       "  0.9516478776931763,\n",
       "  0.9285508394241333,\n",
       "  0.9363666772842407,\n",
       "  0.932153582572937,\n",
       "  0.9337907433509827,\n",
       "  0.9362408518791199,\n",
       "  0.9293181896209717,\n",
       "  0.9350935220718384,\n",
       "  0.9298904538154602],\n",
       " 'val_recall': [0.8477627635002136,\n",
       "  0.7941725254058838,\n",
       "  0.8429790139198303,\n",
       "  0.8349071741104126,\n",
       "  0.8441683650016785,\n",
       "  0.8324758410453796,\n",
       "  0.8417068123817444,\n",
       "  0.8478313088417053,\n",
       "  0.843632161617279,\n",
       "  0.8378302454948425],\n",
       " 'val_MAE': [0.038521572947502136,\n",
       "  0.041853707283735275,\n",
       "  0.036364682018756866,\n",
       "  0.03717649728059769,\n",
       "  0.036127761006355286,\n",
       "  0.03767230361700058,\n",
       "  0.03612224757671356,\n",
       "  0.03598475083708763,\n",
       "  0.03598366305232048,\n",
       "  0.037034157663583755],\n",
       " 'val_auc': [0.9903643131256104,\n",
       "  0.9896727800369263,\n",
       "  0.994096040725708,\n",
       "  0.9942178130149841,\n",
       "  0.9942763447761536,\n",
       "  0.9938105344772339,\n",
       "  0.9945534467697144,\n",
       "  0.9943448901176453,\n",
       "  0.9945080280303955,\n",
       "  0.9938578009605408],\n",
       " 'lr': [0.01,\n",
       "  0.01,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.0019999999,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac2300e",
   "metadata": {},
   "source": [
    "### Testing forest bonitet model\n",
    "### Тестирование модели бонитета леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177367c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test data / загрузка тестовых данных\n",
    "x_test = np.load(r'F:\\Work\\CorrProizv\\x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366fbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load(r'F:\\Work\\CorrProizv\\y_bon_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abab968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model / загрузка модели\n",
    "model = tf.keras.models.load_model(r'E:\\Work\\CorrProizv\\deeplab_bon.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91704918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X_ds, y_ds, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_ds = X_ds\n",
    "        self.y_ds = y_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X_ds) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        X = self.X_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        y = self.y_ds[index*self.batch_size:(index+1)*self.batch_size].astype('float32')\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i] * np.broadcast_to((1-y[i][:,:,0:1]), X[i].shape)\n",
    "        return X, y\n",
    "\n",
    "batch_size = 16\n",
    "test_generator = CustomDataGen(X_ds = x_test, y_ds = y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5040543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11765/11765 [==============================] - 2677s 227ms/step - loss: 0.2658 - accuracy: 0.8849 - precision: 0.9349 - recall: 0.8421 - MAE: 0.0363 - auc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "#testing / тестирование\n",
    "results = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a061f8",
   "metadata": {},
   "source": [
    "### Map of forest bonitets\n",
    "### Карта бонитетов леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086f951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model / загрузка модели\n",
    "model = tf.keras.models.load_model(r'E:\\Work\\CorrProizv\\deeplab_bon.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "855b7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating tiles / генерация тайлов\n",
    "tiles = []\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "x2 = 128\n",
    "y2 = 128\n",
    "for i in range (0,632,1):\n",
    "    for i in range(0,1089,1):\n",
    "        tiles.append((x1,y1,x2,y2))\n",
    "        y1 +=128\n",
    "        y2 +=128\n",
    "    y1=0\n",
    "    y2=128\n",
    "    x1+=128\n",
    "    x2+=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66e9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train, validation and test split / загрузка тренировочного, валидационного и тестового наборов\n",
    "with open(r\"E:\\Work\\CorrProizv\\samples.pickle\", \"rb\") as fp:\n",
    "    samples = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae872ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = samples[:400000]\n",
    "val = samples[400000:500000]\n",
    "test = samples[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9f83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading y data raster as a reference / загрузка файла с обучающими данными для привязки итогового растра\n",
    "y = r'F:\\Work\\CorrProizv\\y_spec2.tif'\n",
    "yband = rio.open(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4156cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating prediction array / создание массива для моделирования\n",
    "y_pred = np.zeros((80896, 139392), dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90781b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for train data / моделирование преобладающей породы для тренировочных даннных\n",
    "x_train = np.load(r'F:\\Work\\CorrProizv\\x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f83c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    prediction = model.predict(x_train[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = train[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca29d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for validation data / моделирование преобладающей породы для валидационных даннных\n",
    "x_val = np.load(r'F:\\Work\\CorrProizv\\x_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0621fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val)):\n",
    "    prediction = model.predict(x_val[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = val[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34bfeeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling tree species for test data / моделирование преобладающей породы для тестовых даннных\n",
    "x_test = np.load(r'F:\\Work\\CorrProizv\\x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92914ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    prediction = model.predict(x_test[i:i+1])\n",
    "    prediction = np.squeeze(np.argmax(prediction, axis=-1))\n",
    "    t = test[i]\n",
    "    t = tiles[t]\n",
    "    y_pred[t[0]:t[2],t[1]:t[3]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbfdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred[:80807, :139330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a311690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving map into raster file / сохранение карты в растровый файл\n",
    "with rio.open(\n",
    "    r'F:\\Work\\CorrProizv\\y_pred_bon.tif',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=y_pred.shape[0],\n",
    "    width=y_pred.shape[1],\n",
    "    count=1,\n",
    "    dtype=y_pred.dtype,\n",
    "    compress = 'deflate',\n",
    "    PREDICTOR = 1,\n",
    "    ZLEVEL=9,\n",
    "    crs=yband.crs,\n",
    "    transform=yband.transform,\n",
    "    nodata = 0\n",
    ") as outfile:\n",
    "    outfile.write(y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4ee5c",
   "metadata": {},
   "source": [
    "#### Tools for tile generation, semantic segmentation and mapping of the modeling results from this notebook are now avaliable in a Python library named [Remote Sensing Processor](https://github.com/simonreise/remote-sensing-processor)\n",
    "#### Инструменты для генерации тайлов, семантической сегментации и картирования результатов моделирования, использованные в этом блокноте доступны в библиотеке Python [Remote Sensing Processor](https://github.com/simonreise/remote-sensing-processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379f5d5-7482-4944-a0de-10f3e6899d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
